<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Wiesen&#39;s Blog</title>
    <link>https://wiesen.github.io/post/</link>
    <description>Recent content in Posts on Wiesen&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 18 Feb 2018 21:31:20 +0800</lastBuildDate>
    
	<atom:link href="https://wiesen.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>python stupid trick</title>
      <link>https://wiesen.github.io/post/python-stupid-trick/</link>
      <pubDate>Sun, 18 Feb 2018 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/python-stupid-trick/</guid>
      <description>python queue: put、get、task_done、join
 Queue.put(item[, block[, timeout]]):
 Put item into the queue. If optional args block is true and timeout is None (the default), block if necessary until a free slot is available. If timeout is a positive number, it blocks at most timeout seconds and raises the Full exception if no free slot was available within that time. Otherwise (block is false), put an item on the queue if a free slot is immediately available, else raise the Full exception (timeout is ignored in that case).</description>
    </item>
    
    <item>
      <title>状态机&amp;事件驱动&amp;eventloop</title>
      <link>https://wiesen.github.io/post/%E7%8A%B6%E6%80%81%E6%9C%BA%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8eventloop/</link>
      <pubDate>Sun, 18 Feb 2018 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/%E7%8A%B6%E6%80%81%E6%9C%BA%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8eventloop/</guid>
      <description>状态机编程思想：“致人 而不致于人” 1. 有限状态机 Difination: 有限状态机（finite-state machine）又称有限状态自动机，简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。
Application:
 自然语言处理：okenizer、parser、regexp 网络协议 游戏设计 自动客服  2. 事件驱动与状态模式 状态模式：
 motivation： 一个业务如果包含多个阶段，而各个阶段之间又并非顺序执行，可能存在复杂的条件跳转。此时，运用状态模式可以帮助我们理清业务逻辑，并发现一些逻辑缺陷。 定义：状态模式（State Pattern）中，类的行为是基于它的状态改变的。这种类型的设计模式属于行为型模式。 意图：允许对象在内部状态发生改变时改变它的行为，对象看起来好像修改了它的类。 主要解决：对象的行为依赖于它的状态（属性），并且可以根据它的状态改变而改变它的相关行为。 何时使用：代码中包含大量与对象状态有关的条件语句。 如何解决：将各种具体的状态类抽象出来。  状态模式包含三个角色：
 Context：环境类又称为上下文类，它是拥有状态的对象，在环境类中维护一个抽象状态类State的实例，这个实例定义当前状态，在具体实现时，它是一个State子类的对象，可以定义初始状态； State：抽象状态类，用于定义一个接口以封装与环境类的一个特定状态相关的行为； ConcreteState：具体状态类是抽象状态类的子类，每一个子类实现一个与环境类的一个状态相关的行为，每一个具体状态类对应环境的一个具体状态，不同的具体状态类其行为有所不同。  事件驱动下的状态模式:
 基于事件驱动的模型，可以使得系统按照预先定义的方式，在状态机中扭转（进入某个状态时，触发什么事件）。 一个完整的业务处理过程包含多个状态迁移。这就需要一个驱动器来管理每一次的状态迁移。 由于状态的迁移是事件驱动的，于是很容易想到运用观察者模式来设计这样一个驱动器。于是，状态是Observable，由许多个Observer订阅，而每个Observer的任务是，当状态机因为某个事件而跳转到某个状态时，向状态机发送下一个事件的通知，直到状态机到达一个终止状态（在这一模型中，终止状态就是没有任何Observer订阅的状态）。  eventloop difination:
 the event loop, message dispatcher, message loop, message pump, or run loop is a programming construct that waits for and dispatches events or messages in a program. It works by making a request to some internal or external &amp;ldquo;event provider&amp;rdquo; (that generally blocks the request until an event has arrived), and then it calls the relevant event handler (&amp;ldquo;dispatches the event&amp;rdquo;).</description>
    </item>
    
    <item>
      <title>2018年秋招面试总结</title>
      <link>https://wiesen.github.io/post/%E7%A7%8B%E6%8B%9B%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/</link>
      <pubDate>Mon, 15 Jan 2018 21:31:33 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/%E7%A7%8B%E6%8B%9B%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/</guid>
      <description>折腾完毕设，记录一下校招的经历、心态和思考，以及对于行业、公司平台、技术方向的个人选择。
首先认清自己的定位，是高校还是企业，也就是读研／博还是工作。刨除所谓学历和名校加成这些无聊因素外，以我个人见闻以及切身体会，国内绝大多数的研究生都不值得读，除非纯学术或者所加入的实验室口碑甚好并且课题方向有意义且合意。否则，对于cs专业来说到工业界工作才能接触到业务的锻炼。无论是工程还是算法都一样。
其次，定位于工业界的话（忽略掉传统外企、国企和银行），需要选择业务／行业方向。包括：电商、游戏、金融、社交、ai（视觉／语音／自动驾驶等）、云计算、基础架构等。
 其中游戏最累但钱最多，电商和云计算次之，基础架构薪资相对少但加班情况也比较少，而ai作为最近三五年最受关注的方向薪酬和发展都是工业界的顶配。 在这里我并不打算以钱多少来区分业务方向的选择。一般来说，不同行业有自身的技术特点，比如游戏是一个很特殊的方向，而云计算中的IaaS和基础架构则与os和计算机系统关系比较紧密，这主要关乎于个人的技术方向。 除了个人技术方向外，我认为选择一个行业看的是未来，也就是预测3～5年后的发展情况。“以史为镜，可以知兴替“。（普通）人作为社会渺小的一员，若以世俗的成功眼光看待行业选择这个问题，那么选择的重要性比能力的重要性要大，这也成为了大多数人口中所说的运气。然而所谓的选择也必须需要先有得到这些选项的可能性，因此先打好基础吧～  我应聘的岗位是后台开发，根据自己擅长的内容初始定位在分布式系统方向。曾经在研一的时候在机器学习方向有点入门，参与过两个小比赛，但由于种种原因未能有时间和精力深入，权当扩展知识面。
在秋招中我面试过的公司比较少，主要是：阿里、腾讯（offer）、网易（offer）、拼多多、华为（offer）、美团（二面放弃）。由于精力不足放弃面试的公司有：美团、网易游戏、百度、招银网络科技等。互联网外企在国内变数较多，长期比较稳定的是ms、Google，其他不好评估，刷题较少的我没在外企投入什么精力……
拼多多 拼多多是秋招第一个面的公司（实际上华为最早但面试都在侃大山，略过），公司给我的感觉就是缺乏人手开发，据说是11-11-6，虽然累但工资高啊很高啊十分高啊……个人对这种电商模式持怀疑态度，尤其是盈利的方向。二面凑巧面到创始人，他直白地跟我说了当前并不需要考虑盈利，有人投钱就行，后续可以接广告投放之类的。
一面：一面面试体验不错，面试官一直在认真听我讲项目内容，还提出几个关键的问题点，几乎也是我之前做项目时也在处理的，第一次碰上这样的面试官我还是挺兴奋的，跟他面了得有100分钟。
 raft如何用于分布式kv数据库中保证数据一致性，主要的疑问点在于读操作是否要进行raft commit 分布式kv数据库中进行slave join／leave时，如何进行hash partition的transfer one loop per thread网络并发模型中，连接的并发数量受限在哪个点 问了一发实际业务场景的问题：如果设计抢购时商品数量的扣除，其中商品数量不能出现小于0  二面：二面面试官后面看新闻脸熟，发现是拼多多的创始人。其面试过程给人感觉相当不友好，一开始问了下实习内容怼了一发，后面手撕算法也莫名开怼。刷了三题leetcode hard后不耐烦的我不想写了。
阿里巴巴：计算平台事业部 捞我的部门是大规模机器学习组。当时托师兄查到后我时相当困惑，我完全没在简历上表明我有机器学习的背景啊……总共是面了三面，莫名其妙到了总监面后就不了了之，吊了我两个多月简历后把我挂了，应该是发现方向不对口吧【不管怎么说一直吊简历太恶心了。
一面：在晚上9点来了个电话面到10点，然后email了一个题目让11点前撕掉，这面试时间十分阿里……一面面试官比较重视基础，基本上针对简历问了点问题，但他通过基础一步步深入，到了后面转换到项目问题我才反应过来。通过这种方法能够测试一个人到底是否理解所做的项目，是一个不错的面试经历。
 进程线程：多线程和多进程的区别，进程和线程的通信方式（不太清楚面试官试图问什么，因为只有进程强调通信，线程本来就共享内存区域只强调同步） 为什么one loop per thread IO模型中采用管道进行master和worker之间的通信（为什么多线程的程序要用多进程的通信方式）：问这个个人觉得有点刁钻……有可能是我讲项目时没讲好，管道主要用于同步（定向唤醒），通信是用thread-safe queue来做的 线程和协程的区别  二面：二面面试官主要问了点Linux内存问题，包括文件系统、内存管理、信号处理等
 内存管理：逻辑地址空间和物理地址的关系  物理内存只有8g，malloc 10g内存会怎样 malloc之后memset呢：swap page；OOM，kill进程：This usually occurs because all available memory, including disk swap space, has been allocated.  网络编程：  libevent、epoll原理 epoll中注册的进程如何被唤醒   网易杭研：云计算存储 网易我一开始在投简历的时候发现c++只有考拉一个部门可以选择（后续hr面告诉我还有很多部门在招c++时，只想吐槽他们的招聘页面能不能好好做），然后我就只好改投云计算存储。分布式存储是我个人比较感兴趣的技术方向，只是网易云计算在业界的知名度比较低。</description>
    </item>
    
    <item>
      <title>分布式事务</title>
      <link>https://wiesen.github.io/post/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Tue, 21 Mar 2017 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</guid>
      <description>Introduction (from Wikipedia)
A distributed transaction is a database transaction in which two or more network hosts are involved.
Usually, hosts provide transactional resources, while the transaction manager is responsible for creating and managing a global transaction that encompasses all operations against such resources.
Distributed transactions, as any other transactions, must have all four ACID (atomicity, consistency, isolation, durability) properties, where atomicity guarantees all-or-nothing outcomes for the unit of work (operations bundle).</description>
    </item>
    
    <item>
      <title>Leveldb: Block Cache</title>
      <link>https://wiesen.github.io/post/leveldb-cache/</link>
      <pubDate>Sat, 25 Feb 2017 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/leveldb-cache/</guid>
      <description>Block Cache (util/cache.cc)：
 Introduction
Cache 的目的：减少磁盘IO，加快 CURD 速度。
leveldb 中的 cache 分为 Table Cache 和 Block Cache 两种，其中 Table Cache 中缓存的是 sstable 的索引数据，Block Cache 缓存的是 Block 数据（可选打开）。
leveldb 中支持用户自己实现 block cache 逻辑，作为 option 传入。默认使用的是内部实现的 LRU。
 基于简单以及效率考虑，leveldb 中实现了一个简单的 hash table（LRUHandle），采用定长数组存放 node，链表解决 hash 冲突。每次 insert 后，如果 node 数量大于数组的容量（期望短的冲突链表长度），就将容量扩大2倍，做一次 rehash； LRU 的逻辑由 LRUCache 控制， insert 和 lookup 时更新链表即可； 由于 levelDB 为多线程，每个线程访问 cache 时都会对 cache 加锁。为了保证多线程安全并且减少锁开销，又将 LRUCache 再做 shard（ShardedLRUCache）。  整体来看：ShardedLRUCache 内部有 16 个 LRUCache（定长），查找 Key 时根据 key 的高四位进行 hash 索引，然后在相应的 LRUCache 中进行查找或更新。当 LRUCache 使用率大于总容量后, 根据 LRU 淘汰 key.</description>
    </item>
    
    <item>
      <title>Leveldb: Storage MemTable</title>
      <link>https://wiesen.github.io/post/leveldb-storage-memtable/</link>
      <pubDate>Tue, 31 Jan 2017 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/leveldb-storage-memtable/</guid>
      <description>Leveldb 存储主要分为 SSTable（磁盘） 和 MemTable（内存，包括 MemTable 和 Immutable MemTable），此外还有一些辅助文件:Manifest, Log, Current。
本篇 blog 主要分析 Memtable：Leveldb一条记录在内存中的形式是什么，记录以怎样的方式被组织。
Memtable (db/skiplist.h,db/memtable.h &amp;amp; memtable.cc)  Introduction MemTable 是 leveldb 的 kv 数据在内存中的存储结构。当 Memtable 写入的数据占用内存到达指定大小 (Options.write_buffer_size)，则自动转换为 Immutable Memtable（只读），同时生成新的 Memtable 供写操作写入新数据。后台的 compact 进程会负责将 immutable memtable dump to disk 生成 sstable。
通过 Memtable 和 Immutable Memtable，Leveldb 可在持久化到磁盘上的同时保持对外服务可用。这种特性是由 Leveldb 的适用场景催生的：Append 写。
Structure &amp;amp; Operation memtable key 的组成参照 Leveldb: Basic Settings。memtable 存储同一 key 的多个版本的数据。KeyComparator 首先按照递增顺序比较 user key，然后安装递减顺序比较sequence number，这两个足以唯一确定一条 entry。</description>
    </item>
    
    <item>
      <title>Leveldb: Log</title>
      <link>https://wiesen.github.io/post/leveldb-storage-log/</link>
      <pubDate>Fri, 27 Jan 2017 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/leveldb-storage-log/</guid>
      <description>Leveldb 存储主要分为 SSTable（磁盘） 和 MemTable（内存，包括 MemTable 和 Immutable MemTable），此外还有一些辅助文件:Manifest, Log, Current。
本篇 blog 主要分析 Log：log 在 Leveldb 中的作用，一条log 在内存中的形式是什么，以怎样的方式被组织。
Log (db/log_format.h&amp;amp;cc,db/log_writer.h&amp;amp;.cc,db/log_reader.h&amp;amp;.cc) Introduction 日志（logging）分两种：
 诊断日志（diagnostic log）：即log4j、glog、log4cxx等常用日志库提供的日志功能 交易日志（transaction log）：即数据库的 write-ahead log、文件系统的journaling等，用于记录状态变更，通过 replay log 可以逐步恢复每一次修改之后的状态。  LevelDb 中的 log 是后者，主要作用是系统故障时进行数据恢复。**利用 WAL（write-ahead log），当故障时 Memtable 中的数据没来得及 Dump 成 SSTable 文件，LevelDB 可根据 log 文件恢复内存数据，保持数据（data和metadata）的持久性。
Format log record 以 block 为单位组织（32k）。写日志时，一致性考虑，并没有以 block 为单位写，而是每次更新均对 log 文件进行 IO，根据 WriteOption::sync 决定是否做强制 sync。读取时以 block 为单位做 IO 以及校验。log 的写入是顺序写，读取只会在启动时发生，不会是性能的瓶颈。
Log entry header 包含三个字段，checksum 是对“类型”和“数据”字段的校验码，为了避免处理不完整或者是被破坏的数据，当 leveldb 读取记录数据时候会对数据进行校验，如果 checksum 相同则说明数据完整无破坏，可以继续后续流程。length 表示 payload 长度，type 字段则指出了每条 log record 和 log block 之间的结构关系，主要有五种类型：ZERO/FULL/FIRST/MIDDLE/LAST，具体结构关系如上图所示。</description>
    </item>
    
    <item>
      <title>Leveldb: Basic Settings</title>
      <link>https://wiesen.github.io/post/leveldb-basic-concept/</link>
      <pubDate>Sat, 26 Nov 2016 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/leveldb-basic-concept/</guid>
      <description>（待完善……）
 Slice(include/leveldb/slice.h)
为操作数据的方便，将数据和长度包装成 Slice 使用，直接操控指针以避免不必要的数据拷贝
class Slice { … private: const char* data_; size_t size_; };  Option(include/leveldb/option.h)
leveldb 中启动时的一些配置，通过 Option 传入，get/put/delete 时，也有相应的 ReadOption/WriteOption。
 Env(include/leveldb/env.h util/evn_posix.h)
考虑到移植以及灵活性，leveldb 将系统相关的处理（文件/进程/时间之类）抽象成 Env，用户可以自己实现相应的接口，作为 Option 传入。默认使用自带的实现。
 varint(util/coding.h)
leveldb 采用了 protocalbuffer 里使用的变长整形编码方法，节省空间。
 ValueType(db/dbformat.h)
leveldb更新（put/delete）某个key时不会操控到db中的数据，每次操作都是直接新插入一份kv数据，具体的数据合并和清除由后台的compact完成。
所以，每次 put 都会添加一份 KV 数据，即使该 key 已经存在；而 delete 等同于 put 空的 value。为了区分 live 数据和已删除的 mock 数据，leveldb 使用 ValueType 来标识：
enum ValueType { kTypeDeletion = 0x0, kTypeValue = 0x1 };  SequenceNumber(db/dbformat.</description>
    </item>
    
    <item>
      <title>Leveldb: Introduction</title>
      <link>https://wiesen.github.io/post/leveldb-introduction/</link>
      <pubDate>Fri, 25 Nov 2016 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/leveldb-introduction/</guid>
      <description>看了不少 blog 分析 leveldb，但很少看到有人从设计原因和策略上进行总结。所以这个系列对 leveldb 的实现做一点设计分析，争取将内部实现逻辑串联起来，至于源码注释之类的网上一扒拉就有很多啦。
Introduction Leveldb 库提供持久层 kv 存储，其中 keys 和values 可以是任意字节数组。目前有 C++，golang 的实现。
作者 Jeff Dean, Sanjay Ghemawat 同时也是设计实现 BigTable 的作者。在 BigTable 中有两个关键部分：master server 和 tablet server。
 master server 负责存储 meta-data，并且调度管理 tablet server； tablet server 负责存储具体数据，并且响应读写操作。  Leveldb 可视为 BigTable 中 tablet server 的简化实现。
Features, Limitations, Performance 详见 leveldb homepage
How to use 详见 leveldb 使用文档
Background 冯诺依曼体系结构的计算机系统主要为两点：存储 + 计算。数据库即为存储方面，依赖于存储硬件特性。
当前磁盘物理结构特性导致 (磁头寻道，旋转延迟)：随机读写慢，连续读写快，相差三个数量级。内存和 SSD 同样表现，只不过原因是：连续读写可预判，因此会被优化 (相差量级也没磁盘那么大)。</description>
    </item>
    
    <item>
      <title>I/O Event Handling Design Patterns</title>
      <link>https://wiesen.github.io/post/io-event-handling-design-patterns/</link>
      <pubDate>Thu, 24 Nov 2016 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/io-event-handling-design-patterns/</guid>
      <description>Introduction System I/O can be blocking, or non-blocking synchronous, or non-blocking asynchronous:
 Blocking I/O means that the calling system does not return control to the caller until the operation is finished a non-blocking synchronous call returns control to the caller immediately  I/O multiplexing mechanisms rely on an event demultiplexor: dispatches I/O events from a limited number of sources to the appropriate read/write event handlers.
There are two non-blocking I/O multiplexing mechanisms: reactor &amp;amp;&amp;amp; proactor.</description>
    </item>
    
    <item>
      <title>TCP粘包问题：分包</title>
      <link>https://wiesen.github.io/post/tcp%E6%96%AD%E5%8C%85%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98/</link>
      <pubDate>Wed, 26 Oct 2016 10:32:46 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/tcp%E6%96%AD%E5%8C%85%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98/</guid>
      <description>Update 2017-01-17 From Muduo：
TCP 是“字节流”协议，其本身没有“消息包”的概念，因此“粘包问题”是个伪命题。但对利用 TCP 进行通信的应用层程序来说，分包是其基本需求。
分包指的是在发送一个消息（message）或者一帧（frame）数据时，通过一定的处理，令接收方能从字节流中识别并截取（还原）出一个个消息包。
对于短连接的 TCP 服务，分包不是问题。只要发送方主动关闭连接，就表示一条消息发送完毕，接收方 read() 返回0，从而得知消息结尾。
对于长连接的 TCP 服务，分包有4种方法：
 消息长度固定（亦即是提前确定包长度，适合定长消息包）； 使用特殊的字符或字符串作为消息的边界，例如 HTTP 协议的 headers 以“\r\n”为字段的分隔符； 在每条消息的头部加一个长度字段，最常见的做法； 利用消息本身的格式来分包，例如 XML 格式的消息中&amp;hellip;的配对，或者json格式中的{&amp;hellip;}的配对。解析这种消息格式通常会用到状态机。  粘包问题 一个完整的消息可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送。粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。
粘包问题是由 TCP 是面向字节流协议因此没有消息边界所引起的。而 UDP 是面向数据报的协议，所以不存在拆包粘包问题。
存在以下特殊情况：
 如果发送数据无结构，如文件传输，这样发送方只管发送，接收方只管接收存储就 ok，不用考虑粘包； 如果利用 TCP 短连接时，不会出现粘包问题； 当发送数据存在一定结构，并且需要维护长连接时，则需要考虑粘包问题；  问题原因 出现拆包粘包现象的原因既可能由发送方造成，也可能由接收方造成:
 要发送的数据大于TCP发送缓冲区剩余空间大小，发生拆包； 待发送数据大于MSS（最大报文长度），TCP在传输前进行拆包； 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，造成粘包; 接收方没能及时地接收缓冲区的数据，造成粘包;  解决方法 解决粘包的方法，是由应用层进行分包处理，本质上就是由应用层来维护消息和消息的边界（即定义自己的会话层和表示层协议）。
本文处理办法：
 发送方在每次发送消息时将数据报长度写入一个int32作为包头一并发送出去, 称之为Encode； 接受方则先读取一个int32的长度的消息长度信息, 再根据长度读取相应长的byte数据, 称之为Decode；
//codec.go package codec import ( &amp;quot;bufio&amp;quot; &amp;quot;bytes&amp;quot; &amp;quot;encoding/binary&amp;quot; ) func Encode(message string) ([]byte, error) { // 读取消息的长度 var length int32 = int32(len(message)) var pkg *bytes.</description>
    </item>
    
    <item>
      <title>Solution to Raspberry Pi ROS rivz Core Dumped</title>
      <link>https://wiesen.github.io/post/solution-to-raspberry-pi-ros-rivz-segmentation-fault/</link>
      <pubDate>Sun, 18 Sep 2016 17:32:46 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/solution-to-raspberry-pi-ros-rivz-segmentation-fault/</guid>
      <description>Recently I installed ROS on Raspberry Pi2 (both Jessie and Ubuntu 14.04) in order to implement SLAM algorithm on it. However when runs the rviz (rosrun rviz rviz) I get core dumped message.
After searching I found the solution here. What I do is upgrade libpcre3 to 3_8.35 (upgrade collada-dom to 2.4.4 does not help). Here is the download link.
I confirm that rviz now works properly on my Raspberry Pi2 running the official ubuntu 14.</description>
    </item>
    
    <item>
      <title>MIT 6.824: Lab 4 Sharded KeyValue Service Implementation</title>
      <link>https://wiesen.github.io/post/mit-6.824-lab4-sharded-keyvalue-service/</link>
      <pubDate>Fri, 09 Sep 2016 17:32:46 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/mit-6.824-lab4-sharded-keyvalue-service/</guid>
      <description>lab4 是基于 lab2 和 lab3 实现的 Raft Consensus Algorithm 之上实现 Sharded KeyValue Service。主要分为两部分：
 Part A：The Shard Master Part B: Sharded Key/Value Server  除了最后一个 challenge test case TestDelete() 以外，目前代码其余都可以 pass。但偶尔会 fail 在 unreliable test case，目前的定位是 raft 的实现还有点 bug。
Code Link:
 PART A PART B  Architecture lab4 的架构是典型的 M/S 架构（a configuration service and a set of replica groups)，不过实现十分基础，很多功能没有实现：1) shards 之间的传递很慢并且不允许 concurrent client acess；2) 每个 raft group 中的 member 不会改变。</description>
    </item>
    
    <item>
      <title>Robotics: Estimation and learning</title>
      <link>https://wiesen.github.io/post/robotics-estimation-and-learning/</link>
      <pubDate>Tue, 16 Aug 2016 17:32:46 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/robotics-estimation-and-learning/</guid>
      <description>Course Link: One of the course of Robotics in Coursera from the University of Pennsylvania. It is helpful to learn the classical algorithm of robotics.
Here are some course notes in Chinese collected from Zhihu. These notes introduce algorithm in a little more detail than course.
However, the code in these notes has bug and even can not run normally, which are no worthy of learning. The code in my GitHub pass all homeworks.</description>
    </item>
    
    <item>
      <title>MIT 6.824: lab3 Fault-Tolerant Key/Value Service Implementation</title>
      <link>https://wiesen.github.io/post/mit-6.824-lab3-fault-tolerant-kvservice-implementation/</link>
      <pubDate>Sat, 06 Aug 2016 17:32:46 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/mit-6.824-lab3-fault-tolerant-kvservice-implementation/</guid>
      <description>lab3 是基于 lab2 实现的 Raft Consensus Algorithm 之上实现 KV Service。主要分为两部分：
 Part A：Key/value service without log compaction，即实现基本的分布式存储服务。 Part B: Key/value service with log compaction，即在 Part A 基础上实现 log compaction。  代码分别可以 pass 各个 test case，但所有一起跑时有时会卡在 TestPersistPartition() 这里，初步猜测是 raft 的实现还有点 bug。
Code Link
Part A：Key/value service  KV Database Client API
key/value database 的 client API 必须满足以下要求：
 保证仅执行一次(at most once semantics)：API 必须为每个 Client 及 每个 Request 赋予唯一的 id； 必须向使用该 API 的应用提供 sequential consistency：对于每个 Client，仅有一条 Request RPC 在显式执行(利用 lock 实现)；  此外，API 应当一直尝试向 key/value server 发起 RPC 直到收到 positive reply；并且记住 leader id，从而尽可能避免失败次数。</description>
    </item>
    
    <item>
      <title>MIT 6.824: lab2 Raft Consensus Algorithm Implementation</title>
      <link>https://wiesen.github.io/post/mit-6.824-lab2-raft-consensus-algorithm-implementation/</link>
      <pubDate>Fri, 10 Jun 2016 21:32:46 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/mit-6.824-lab2-raft-consensus-algorithm-implementation/</guid>
      <description>分布式一致性协议原理 分布式一致性协议关注的问题：普通服务器和网络的不可靠，导致分布式系统中的数据不一致
分布式一致性协议的作用：令一个机器集群可以在部分主机故障或不可用时仍能似单机一样提供正常服务（并不是要求所有节点在任何时刻状态完全一致）
 强调在网络分区或节点异常时，是因为如果不考虑这种异常状况，一致性是非常容易保证的，单节点即可。而一致性协议所要做的就是在容忍异常的情况下保证一致。 这里的一致是对集群外部使用者而言的，将整个集群看做一个整体。  分布式一致性协议的优点：
 保证在非拜占庭环境下的可靠性和一致性 只要大多数主机正常并能互相通信则能提供正常服务 不依赖时间来确定数据的一致性  Quorum与Paxos，Raft等一致性协议大多使用了Quorum机制，但仅仅依靠 Quorum(R+W&amp;gt;N) 机制无法保证一致性。
Raft 基于Quorum机制，将一致性问题分为了三个相对独立的子问题，分别是：
 Leader election：组成一个 Raft 集群至少需要三台机器，并限制每一时刻最多只能有一个节点可以发起 entry，即为 leader，以简化了一致性的实现。当前 leader 崩溃时，集群中必须选举出一个新的 leader 才能继续发起 entry。该子问题需要解决以下两个问题：  如何保证任何时候最多只有一个 leader 节点； 当 leader 节点异常时如何尽快的选择出新的 leader 节点；  Log replication：leader 必须接受来自 clients 的 log entries，并且将其 replicate 到集群机器中，强制其余 logs 与其保持一致，以保证后续 Leader 节点变化后依然能够使得整个集群对外保持一致。该子问题需要解决以下两个问题：  Follower 以与 Leader 节点相同的顺序依次执行每个 committed entry； 每个 committed entry 必须有足够多的成功副本，来保证后续的访问一致；  Safety：Raft 中最关键的 safety property 是 State Machine Safety Property，亦即是，当任一机器 apply 了某一特定 log entry 到其 state machine 中，则其余服务器都不可能 apply 了一个 index 相同但 command 不同的 log。具体来说即添加了以下两个限制：  leader election 限制：为了避免数据从 Follower 到 Leader 的反向流动带来的复杂性，Raft 限制新 Leader 一定是当前 Log 最新的节点，即其拥有最多最大 term的 Log Entry log replication 限制：Leader 只能对自己本 Term 的 entry 采用统计大多数的方式进行 commit，而旧 Term 的 entry 则利用 “committed entry 之前的所有 Log entry 都已顺序 commit”的机制来提交（归纳法可得）   差不多依据上述划分，6.</description>
    </item>
    
    <item>
      <title>微软2016校招在线笔试题解</title>
      <link>https://wiesen.github.io/post/%E5%BE%AE%E8%BD%AF2016%E6%A0%A1%E6%8B%9B%E5%9C%A8%E7%BA%BF%E7%AC%94%E8%AF%95%E9%A2%98%E8%A7%A3/</link>
      <pubDate>Fri, 15 Apr 2016 21:31:33 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/%E5%BE%AE%E8%BD%AF2016%E6%A0%A1%E6%8B%9B%E5%9C%A8%E7%BA%BF%E7%AC%94%E8%AF%95%E9%A2%98%E8%A7%A3/</guid>
      <description>微软2016校招在线笔试题解 题目地址：mstest2016april1
感受：一定要理解好题意，注意细节。另外微软特别喜欢考察反向思维。
A. Font Size 选择一个最大字号刚好可以令页数不超过给定阈值P。
逻辑理清即可。页由行组成，行由字符组成，其中字符为方形。需要注意的地方是：(1) 每段都从新的一行开始；(2) 每页至少显示一个字符。
字号是整数，可以暴力求解遍历直到合适字号，单点时间复杂度为O(10^6)，没有超过题目限制。但如果题目再卡紧点就有点危险了，所以更好的方法是利用二分查找，注意好边界条件即可。
编码思路如下：
1.确定字号最小值为1，最大值为 min(W, H)
2.求字号为中值 m 时的页数：每段所占行数 a[i]/(W/m)，对所有段所占行数求和，最后求所占页数 total/(H/m)。
3.当所占页数大于等于阈值P，则r=m，小于则l=m+1，直到l&amp;gt;=r。注意等于阈值P时并不代表已经找到解，字号可能还能增大。
4.解为 r-1。
B. 403 Forbidden 题目的要求是进行 IP 地址匹配，返回最先（序号最小）匹配到的规则的动作，没有匹配的规则则返回 allow。
一种方法是利用前缀树求解。建树方法: 在插入新规则 new 时，在该规则的前缀路径上（含等长）已有规则 old，意味着 old 屏蔽了new，直接丢弃新规则new。 由此，在匹配一个 IP 地址时，只需要返回前缀树上匹配这个 IP 地址的最长规则。
建树时间复杂度为 O(N)，匹配一次只需要常数时间，整体时间复杂度为 O(min{N,M})。
C. Demo Day 动态规划水题，起始位置为 (1,1)，动作为向下或向右，考虑好各个状态转移,并且注意边界特殊情况即可。时间复杂度为 O(N*M)。
DP[i][j][k] 含义为：在第 i 行 第 j 列时，向 k 方向前进需要改变多少个格子 (1&amp;lt;=i&amp;lt;=N, 1&amp;lt;=j&amp;lt;=M, k=right or down)。
DP[i][j][right] = min{DP[i][j-1][right], DP[i-1][j][down] + (i + 1 &amp;lt; n &amp;amp;&amp;amp; maze[i+1][j] !</description>
    </item>
    
    <item>
      <title>Flat Datacenter Storage Paper Review</title>
      <link>https://wiesen.github.io/post/flat-datacenter-storage-paper-review/</link>
      <pubDate>Wed, 30 Mar 2016 21:33:37 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/flat-datacenter-storage-paper-review/</guid>
      <description>A review for paper Nightingale E B, Elson J, Fan J, et al. Flat datacenter storage[C]//Presented as part of the 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12). 2012: 1-15.
Introduction What is FDS?
 Flat Datacenter Storage (FDS) is a high-performance, fault-tolerant, large-scale, locality-oblivious blob store. Using a novel combination of full bisection bandwidth networks, data and metadata striping, and** flow control**, FDS multiplexes an application’s large-scale I/O across the available throughput and latency budget of every disk in a cluster.</description>
    </item>
    
    <item>
      <title>Chain Replication Paper Review</title>
      <link>https://wiesen.github.io/post/chain-replication-paper-review/</link>
      <pubDate>Sat, 19 Mar 2016 21:33:09 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/chain-replication-paper-review/</guid>
      <description>本文是读完 Van Renesse R, Schneider F B. Chain Replication for Supporting High Throughput and Availability[C]//OSDI. 2004. 的总结。
Summary Chain replication is a new approach to coordinating clusters of fail-stop storage servers.
Chain replication 采用 ROWAA (read one, write all available) 方法, 具有良好的 Scalability.
该方法目的是, 不以牺牲强一致性为代价来实现高吞吐和高可用, 从而提供分布式存储服务.
A Storage Service Interface Clients 发送 query 或 update 操作 request
The storage service 为每个 request 生成 reply 发送会 client 告知其已经接收或已经处理完成, 从而 client 可以得知某 request 是否接收成功以及是否处理完成.</description>
    </item>
    
    <item>
      <title>快速排序笔记</title>
      <link>https://wiesen.github.io/post/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 15 Mar 2016 21:31:20 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E7%AC%94%E8%AE%B0/</guid>
      <description>快排最引人注目的特点是原地排序（只需要一个很小的辅助栈），且将长度为 N 的数组排序所需的时间和 NlgN 成正比。 而快排的主要缺点是非常脆弱，在实现时必须非常小心才能避免性能低下。
同前述一致：以 C++ 实现,仅针对 vector 进行操作, 并且遵循 C++ 左闭右开的区间标准: [a,b)。
基本算法 快排也是一种分治的排序算法，快排与归并排序是互补的：
 归并排序将数组分成两个子数组分别排序，再将有序子数组归并以将整个数组排序，其递归调用发生在处理整个数组之前； 而快排则是先确定 key 的位置，而后当两个子数组都有序时则整个数组即有序，其递归调用发生在处理整个数组之后。  快排的关键在划分，划分过程需要使得数组满足以下三个条件：
 对于某个 key，a[key] 已经排定； [low,key) 中所有元素都不大于 a[key]； [key,high) 中所有元素都不小于 a[key]。   据此，快排的基本思想是:
 选取一个元素作为切分元素 key，然后从数组左端开始向右扫描直到找到一个大于等于它的元素，再从数组右端开始向左扫描直到找到一个小于等于它的元素，而后交换它们的位置; 如此继续，就可以保证左指针 left 的左侧元素都不大于 key，右指针 right 的右侧都不小于 key; 当左右指针相遇时 （left &amp;gt;= right），将切分元素 key 与左子数组最右元素（也就是 right 最终停下的位置）交换然后返回划分位置 right 即可。
int Partition(std::vector&amp;lt;T&amp;gt; &amp;amp;vec, int low, int high) { int left = low, right = high; while (true) { // Avoid subscript beging out of range while (vec[++left] &amp;lt; vec[low]) if (left == high - 1)break; while (vec[low] &amp;lt; vec[--right]) if (right == low)break; // Terminate the loop if (left &amp;gt;= right)break; std::swap(vec[left], vec[right]); } std::swap(vec[low], vec[right]); return right; }   快排中有若干细节问题值得注意，否则会导致实现错误或者性能下降:</description>
    </item>
    
    <item>
      <title>归并排序笔记</title>
      <link>https://wiesen.github.io/post/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 10 Mar 2016 21:24:46 +0800</pubDate>
      
      <guid>https://wiesen.github.io/post/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%AC%94%E8%AE%B0/</guid>
      <description>归并排序是一种渐近最优的基于比较排序的算法, 意即: 其在最坏情况下的比较次数和任意基于比较的排序算法所需的最少比较次数都是~NlgN。其主要的优点是可以保证将任意长度为 N 的数组排序的时间复杂度为 O(NlgN); 其主要缺点是空间复杂度为 O(N)。
这里均以 C++ 实现, 为了避免陷入到语言细节里所以仅针对 vector 进行操作, 并且遵循 C++ 左闭右开的区间标准: [a,b)。值得注意的是区间表示一致性这个细节对针对数组和搜索(如二分查找)的算法有着举足轻重的影响。
至于倾向于 [a,b) 左闭右开区间表示的原因可参考链接。简单来说主要原因有二: 一是 end-begin 即可得到区间大小; 二是当区间退化为 0 时包含左界更加&amp;rdquo;natural&amp;rdquo;。
自顶向下的归并排序 递归实现的归并排序是算法设计中分治思想的典型应用。
主要是两个函数: 由 MergeSort() 负责递归调用, Merge() 负责归并。
 优化一: 对小规模子数组使用插入排序
递归会使小规模问题中方法的调度过于频繁, 而插入或者选择在小数组上比归并要快, 所以改进对小规模子数组的处理方法可以改进整个算法。根据经验, 使用插入处理小规模子数组(&amp;lt;15)可将归并的运行时间缩短10%~15%。
 优化二: 测试子数组是否有序
添加一个判断条件: if (a[mid] &amp;gt; a[mid+1]) 再进行 Merge() 操作, 否则数组已经是有序的。进行此优化可以令任意有序的子数组算法时间复杂度变为线性。
 优化三: 不将元素复制到辅助数组
在递归调用的每个层次交换输入数组和辅助数组的角色, 可节省将数组元素复制到用于归并的辅助数组的时间(无法节省空间)。
template&amp;lt;class T&amp;gt; void Merge(std::vector&amp;lt;T&amp;gt; &amp;amp;src, std::vector&amp;lt;T&amp;gt; &amp;amp;dest, int nHead, int nMid, int nEnd) { int nLeftIndex = nHead, nRightIndex = nMid; for (int i = nHead; i &amp;lt; nEnd; ++i){ // Detail: Use range[nHead, nEnd) if (nLeftIndex &amp;gt;= nMid) dest[i] = src[nRightIndex++]; else if (nRightIndex &amp;gt;= nEnd) dest[i] = src[nLeftIndex++]; else if (src[nLeftIndex] &amp;lt; src[nRightIndex]) dest[i] = src[nLeftIndex++]; else dest[i] = src[nRightIndex++]; } } template&amp;lt;class T&amp;gt; void MergeSort(std::vector&amp;lt;T&amp;gt; &amp;amp;src, std::vector&amp;lt;T&amp;gt; &amp;amp;dest, int nHead, int nEnd) { // if (nEnd - nHead &amp;lt;= 1) return; // Before optimizing // Optimization 1: Use InsertSort when small scale if (nEnd - nHead &amp;lt;= 15) { InsertSort(dest, nHead, nEnd); return; } int nMid = (nHead + nEnd) / 2; // Optimization 2: Avoid copying to auxiliary array MergeSort(dest, src, nHead, nMid); MergeSort(dest, src, nMid, nEnd); // Optimization 3: If the sub-array is sorted then skip merge if (src[nMid - 1] &amp;lt;= src[nMid]){ std::copy(src.</description>
    </item>
    
  </channel>
</rss>