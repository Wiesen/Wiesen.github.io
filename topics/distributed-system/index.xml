<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Distributed System on Wiesen&#39;s Blog</title>
    <link>http://wiesen.github.io/topics/distributed-system/index.xml</link>
    <description>Recent content in Distributed System on Wiesen&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <atom:link href="http://wiesen.github.io/topics/distributed-system/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>MIT 6.824: Lab 4 Sharded KeyValue Service Implementation</title>
      <link>http://wiesen.github.io/post/MIT-6.824-Lab4-Sharded-KeyValue-Service/</link>
      <pubDate>Fri, 09 Sep 2016 17:32:46 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/MIT-6.824-Lab4-Sharded-KeyValue-Service/</guid>
      <description>

&lt;p&gt;lab4 是基于 lab2 和 lab3 实现的 Raft Consensus Algorithm 之上实现 Sharded KeyValue Service。主要分为两部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Part A：The Shard Master&lt;/li&gt;
&lt;li&gt;Part B: Sharded Key/Value Server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了最后一个 challenge test case &lt;code&gt;TestDelete()&lt;/code&gt; 以外，目前代码其余都可以 pass。但偶尔会 fail 在 unreliable test case，目前的定位是 raft 的实现还有点 bug。&lt;/p&gt;

&lt;p&gt;Code Link:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Wiesen/MIT-6.824/tree/master/2016/shardmaster&#34;&gt;PART A&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Wiesen/MIT-6.824/tree/master/2016/shardkv&#34;&gt;PART B&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;

&lt;p&gt;lab4 的架构是典型的 M/S 架构（a configuration service and a set of replica groups)，不过实现十分基础，很多功能没有实现：1) shards 之间的传递很慢并且不允许 concurrent client acess；2) 每个 raft group 中的 member 不会改变。&lt;/p&gt;

&lt;p&gt;configuration service&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;由若干 shardmaster 利用 raft 协议保证一致性的集群；&lt;/li&gt;
&lt;li&gt;管理 configurations 的顺序：每个 configuration 描述 replica group 以及每个 group 分别负责存储哪些 shards；&lt;/li&gt;
&lt;li&gt;响应 Join/Leave/Move/Query 请求，并且对 configuration 做出相应的改变；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;replica group&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;由若干 shardkv 利用 raft 协议保证一致性的集群；&lt;/li&gt;
&lt;li&gt;负责具体数据的存储（一部分），组合所有 group 的数据即为整个 database 的数据；&lt;/li&gt;
&lt;li&gt;响应对应 shards 的 Get/PutAppend 请求，并保证 linearized；&lt;/li&gt;
&lt;li&gt;周期性向 shardmaster 进行 query 获取 configuration，并且进行 migration 和 update；&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;part-a-the-shard-master&#34;&gt;Part A：The Shard Master&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;RPC Join/leave/Move/Query&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Client:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;at most once semantics：每个 Client 及 每个 Request 赋予唯一的 id；&lt;/li&gt;
&lt;li&gt;sequential consistency：对于每个 Client，仅有一条 Request RPC 在显式执行；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Server:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;异步：开一个 goroutine 来监听和处理 accept entry，与各 RPC 中的 start entry 分离，利用 channel 进行同步和通信；&lt;/li&gt;
&lt;li&gt;at most once semantics：主要针对写操作，本文在 accept operation 处进行 duplicated check (也可以在 start operation 处再加一层)，对于重复的 request，仅向 client 回复操作结果；&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Rebanlancing&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;lab4 对 shards 分配的要求是: divide the shards as evenly as possible among the groups, and should move as few shards as possible to achieve that goal.&lt;/p&gt;

&lt;p&gt;最直接的做法是: 首先计算每个 replica group 分配多少个 shards ( &lt;code&gt;quota = num_of_shards / num_of_group&lt;/code&gt;, &lt;code&gt;remain = num_of_shards - num_of_group * quota&lt;/code&gt;，然后依据 &lt;code&gt;num_of_server&lt;/code&gt; 对 replica group 进行排序，server 数量多的 group 分配 shards 个数 &lt;code&gt;quota + 1&lt;/code&gt;，其余分配 &lt;code&gt;quota&lt;/code&gt; )，最后把 shards 从多的 group 移动到少的 group。&lt;/p&gt;

&lt;p&gt;然而，在 go 中实现上面的做法并不是那么 clean，很多特性在语言层面上并不支持，比如: 1) get map.keys(); 2) 根据特定的字段进行排序等，自行实现实在麻烦。&lt;/p&gt;

&lt;p&gt;因此，由于 lab 中只有 join/leave 会造成 imbalance，并且 group 是逐个 join/leave。所以 simple first，首先统计 prior config 中每个 group 有多少个 shards，并且计算 present config 中平均每个 group 分配多少个 shards (&lt;code&gt;quota = num_of_shards / num_of_group&lt;/code&gt;)，然后循环将 max_shards_group/leaving_group 中的 shards 分配给 joining_group/min_shards_group.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;part-b-sharded-key-value-server&#34;&gt;Part B: Sharded Key/Value Server&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;RPC PutAppend/Get/TransferShard&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hint: Think about how the shardkv client and server should deal with ErrWrongGroup. Should the client change the sequence number if it receives ErrWrongGroup ? Should the server update the client state if it returns ErrWrongGroup when executing a Get / Put request?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;绝大部分与 Part A 一样，除了 ErrWrongGroup 的异常处理。&lt;/p&gt;

&lt;p&gt;当 server 发现 ErrWrongGroup 时，不需要 update client state；当 client 收到 ErrWrongGroup 时，不需要改变 operation sequence number，换个 group 继续 request 即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Migrating Shard&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hint: When groups move shards, they need to move some duplicate detection state as well as the key/value data. Think about how the receiver of a shard should update its own duplicate detection state. Is it correct for the receiver to entirely replace its state with the received one?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;假设&lt;/strong&gt;: configuration 由 cfg1 —&amp;gt; cfg2，shard S1 由 G1 -&amp;gt; G2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;How to migrate - push or pull&lt;/strong&gt;: 这时应该由 G1 push S1 还是由 G2 pull S1？一般来说，G2 完成 reconfig 操作后，随时会有针对 migrated shard 的 get/put/append 操作。如果由 G1 push S1，那么就无法保证 migrated shard 什么时候完成，出现错误。所以应该由 G2 在进行 reconfig 时进行 pull;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Response to migration&lt;/strong&gt;: 由于 lab 中 group 是逐个 join/leave，同一个 group 不会同时迁入和迁出 shards，亦即是迁入和迁出 shards 的 groups 不会相交。因此当 G1 处于 cfg2 时，G1 已经不再负责 S1，之后可随时响应 migration 迁出 S1。亦即是：当 G1.cfg.num &amp;gt; G2.cfg.num 才能响应 migration，否则必须等待 G1 更新完毕 (避免互相请求出现死锁)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reconfiguration&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hint: Process re-configurations one at a time, in order.&lt;/p&gt;

&lt;p&gt;Hint: When group G1 needs a shard from G2 during a configuration change, does it matter at what point during its processing of log entries G2 sends the shard to G1?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Detect&lt;/strong&gt;: 开一个 goroutine 来周期性地向 shardmaster query 最新的 configuration (由 group leader 完成)，当发现 configuration 更新时 (one by one in order)，即向其余 group 获取需要的 shards (migrating shard)；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;When to reconfigurate&lt;/strong&gt;: Reconfiguration operation 仅仅是 group leader 从 shardmaster 获取到的 operation proposal，新的 configuration 什么时候生效是由各 group 自身决定，本文的实现是当 group 获取到需要的 shards 后再进行 reconfiguration update。因此会出现当 client 根据新的 configuration 向 shardkv 发起 request 时，各个 group 都还没完成 configuration update。不过这并没什么影响，我们可以让 client 一直 loop 向每个 replica group 发起 request (当然是一直被拒)，直到目标 group 完成 reconfiguration update;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Reconfiguration operation 会影响到 PutAPpend/Get，因此同样需要利用 raft 保证 group 内的一致性，确保集群内完成了之前的操作后同时进行 Reconfiguration；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Replace What&lt;/strong&gt;: 包括 config，StoreShard (data) 以及 Ack (duplicate detection)，其中 Ack 不是 replace entirely，仅当 kv.ack[clientId] &amp;lt; migration.Ack[clientId] 才更新；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bluesea147/6.824/blob/master/src/shardmaster/server.go&#34;&gt;bluesea147/6.824/shardmaster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/bluesea147/6.824/blob/master/src/shardkv/server.go&#34;&gt;bluesea147/6.824/shardkv&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>MIT 6.824: lab3 Fault-Tolerant Key/Value Service Implementation</title>
      <link>http://wiesen.github.io/post/MIT-6.824-lab3-Fault-Tolerant-KVService-Implementation/</link>
      <pubDate>Sat, 06 Aug 2016 17:32:46 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/MIT-6.824-lab3-Fault-Tolerant-KVService-Implementation/</guid>
      <description>

&lt;p&gt;lab3 是基于 lab2 实现的 Raft Consensus Algorithm 之上实现 KV Service。主要分为两部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Part A：Key/value service without log compaction，即实现基本的分布式存储服务。&lt;/li&gt;
&lt;li&gt;Part B: Key/value service with log compaction，即在 Part A 基础上实现 log compaction。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;代码分别可以 pass 各个 test case，但所有一起跑时有时会卡在 &lt;code&gt;TestPersistPartition()&lt;/code&gt; 这里，初步猜测是 raft 的实现还有点 bug。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Wiesen/MIT-6.824/tree/master/2016/kvraft&#34;&gt;Code Link&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;part-a-key-value-service&#34;&gt;Part A：Key/value service&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;KV Database Client API&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;key/value database 的 client API 必须满足以下要求：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;保证仅执行一次(at most once semantics)：API 必须为每个 Client 及 每个 Request 赋予唯一的 id；&lt;/li&gt;
&lt;li&gt;必须向使用该 API 的应用提供 sequential consistency：对于每个 Client，仅有一条 Request RPC 在显式执行(利用 lock 实现)；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此外，API 应当一直尝试向 key/value server 发起 RPC 直到收到 positive reply；并且记住 leader id，从而尽可能避免失败次数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Raft Handler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Raft Server Handler 需要满足以下要求：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;保证每个 client 的每条 request (主要是写操作) 仅执行一次：对于重复的 request，仅向 client 回复操作结果；&lt;/p&gt;

&lt;p&gt;本文为每个 client 维护一个已执行的最大 requestId 值 (&lt;code&gt;map[int64]int&lt;/code&gt;)，从而检测并过滤重复的 request&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; func (kv *RaftKV) isDuplicated(clientId int64, requestId int) bool {
    kv.mu.Lock()
    defer kv.mu.Unlock()
    if value, ok := kv.ack[clientId]; ok &amp;amp;&amp;amp; value &amp;gt;= requestId {
        return true
    }
    kv.ack[clientId] = requestId
    return false
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在向 raft 添加等待结果的同时，需要一直监听返回管道 &lt;code&gt;applyCh&lt;/code&gt; ，以接收已经达成一致的 entry；&lt;/p&gt;

&lt;p&gt;我们开一个 goroutine &lt;code&gt;update()&lt;/code&gt; 一直监听 &lt;code&gt;applyCh&lt;/code&gt;，并且基于 entry 的 index 各维护一个管道 (&lt;code&gt;map[int]chan Result&lt;/code&gt;)，存放在 raft servers 间达成一致的 entry，等待 handler 的读取或者直接丢弃。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; func (kv *RaftKV) Update() {   // ignore snapshot
    for true {
        msg := &amp;lt;- kv.applyCh
        request := msg.Command.(Op)
        var result Result
        ...                     // set variable value
        result.reply = kv.Apply(request, kv.isDuplicated(clientId, requestId))
        kv.sendResult(msg.Index, result);
    }
  }

 func (kv *RaftKV) sendResult(index int, result Result) {
    kv.mu.Lock()
    defer kv.mu.Unlock()
    if _, ok := kv.messages[index]; !ok {
        kv.messages[index] = make(chan Result, 1)
    } else {
        select {
        case &amp;lt;- kv.messages[index]:
        default:
        }
    }
    kv.messages[index] &amp;lt;- result
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;key/value server 向 raft 添加一个 entry 后，阻塞读取其 index 对应的管道，直到接收到结果或者超时（本文设置为 1s）。当接收到的结果 clientId 或者 requestId 不一致时，表明 leader 已经发生了更替，由 Client 重新向 server 发起 RPC。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;有一个需要注意的地方是，&lt;strong&gt;必须利用 &lt;code&gt;gob.Register()&lt;/code&gt; 注册需要通过 RPC 发送的结构体&lt;/strong&gt;，这样结构体才能够被解析，否则发送过去就是一个 &lt;code&gt;nil&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;part-b-log-compaction&#34;&gt;Part B: log compaction&lt;/h2&gt;

&lt;p&gt;随着运行时间的增加，raft server 的 log table 会越来越大，不仅会占用越多空间，而且一旦出现宕机则 replay 也需要越长时间。比如不加以管理，则势必影响服务的可用性。为了令其维持合理长度不至于无限增加，必须在适当的时候抛弃旧的 log entries。&lt;/p&gt;

&lt;p&gt;这部分主要有以下实现点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Take snapshots independently&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里各个 raft server 各自独立进行 snapshot，而这并不会影响 raft 的一致性。因为数据始终从 leader 流向 follower，各个 raft server 只是将数据重新组织而已。&lt;/p&gt;

&lt;p&gt;这部分主要解决的问题是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(When)&lt;/strong&gt; 什么时候进行 snapshot：由 key/value server 检测所连接的 raft server 存储大小是否即将超过阈值，然后通知该 raft server 进行 snapshot；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(What)&lt;/strong&gt; 在 snapshot 中存储什么信息：如 raft-extended paper Figure 12 里的描述，主要包括当前 &lt;code&gt;LastIncludedIndex&lt;/code&gt;, &lt;code&gt;LastIncludedTerm&lt;/code&gt; 以及 &lt;code&gt;data&lt;/code&gt;，其中 &lt;code&gt;data&lt;/code&gt; 是状态机状态，来自于 key/value server。一点需要注意的是，必须保存用于检测 duplicate client requests 的数据，因此 &lt;code&gt;data&lt;/code&gt; 在这里包括整个数据库和检测重复的 map；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(How)&lt;/strong&gt; 如何令 raft 在仅有最新一部分 log 的情况下保持正常运行：主要是将 &lt;code&gt;rf.logTable[0]&lt;/code&gt; 作为起始 entry，一旦有 follower 请求更老的 entries，则应该发送 InstallSnapshot RPC；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要增加和修改的地方如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;update()&lt;/code&gt;： 在每次接收到 raft server 返回的 entry 时，检测 raft state size，若临近阈值则将封装 &lt;code&gt;data&lt;/code&gt;，然后通知 raft 从 &lt;code&gt;entry.index&lt;/code&gt; 开始 snapshotting；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;StartSnapshot(data []byte, index int)&lt;/code&gt;：删除 log table 中序号小于 &lt;code&gt;index&lt;/code&gt; 的 entries，并且在 &lt;code&gt;data&lt;/code&gt; 后添加最后包括的 entry 的相关数据，最后持久化保存；&lt;/li&gt;
&lt;li&gt;其余琐碎并且细节的修改还包括：对 entry 增加一个字段 &lt;code&gt;index&lt;/code&gt;，记录其在所在 &lt;code&gt;term&lt;/code&gt; 的序号，在需要对 log table 进行操作地方（尤其是涉及对 entry 在 table 中的位置），注意 log table 中的起始序号：&lt;code&gt;baseLogIndex := rf.logTable[0].Index&lt;/code&gt; 再进行处理；&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;InstallSnapshot RPC&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当一个 follower 远远落后于 leader（即无法在 log table 中找到匹配的 entry），则应该发送 InstallSnapshot RPC。我们参考 raft-extended paper Figure 13 设置数据结构，但有所简化：由于 lab 里的 Snapshot 不大，因此没有设置 chunk，也就是不需要对 snapshot 进行切分。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;InstallSnapshot RPC sender&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当 heartbeat timeout 时 leader 检测 follower 的 log table 是否与自身一致，如果 &lt;code&gt;rf.nextIndex[server] &amp;lt;= baseLogIndex&lt;/code&gt;，则 leader 应该向 follower &lt;code&gt;server&lt;/code&gt; 发送 InstallSnapshot RPC,否则 &lt;code&gt;AppendEntries&lt;/code&gt;。这里发送设置好相应的参数即可，跟发送 &lt;code&gt;AppendEntries&lt;/code&gt; 差不多，收到正确的 reply 则 更新 &lt;code&gt;matchIndex&lt;/code&gt; 和 &lt;code&gt;nextIndex&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; baseLogIndex := rf.logTable[0].Index
 if rf.nextIndex[server] &amp;lt;= baseLogIndex {
    ...             // set variable value
    var reply InstallSnapshotReply
    if rf.sendInstallSnapshot(server, args, &amp;amp;reply) {
        if rf.role != Leader {
            return
        }
        if args.Term != rf.currentTerm || reply.Term &amp;gt; args.Term {
            if reply.Term &amp;gt; args.Term {
                ... // update term and role
            }
            return
        }
        rf.matchIndex[server] = baseLogIndex
        rf.nextIndex[server] = baseLogIndex + 1
        return
    }
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;InstallSnapshot RPC handler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;由于没有设置 chunk，所以这里的 handler 比 paper 中的 implementation 简化不少：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先检测 &lt;code&gt;args.Term &amp;lt; rf.currentTerm&lt;/code&gt;，满足则直接返回自身 term 即可；&lt;/li&gt;
&lt;li&gt;其次检测 &lt;code&gt;rf.currentTerm &amp;lt; args.Term&lt;/code&gt;,满足则更新自身 term 和 role;&lt;/li&gt;
&lt;li&gt;然后更新自身的 log table，把 LastIncluded entry 前的丢弃；&lt;/li&gt;
&lt;li&gt;最后将 snapshot 发送给 key/value server，以重置数据库数据，更新状态。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;最后&#34;&gt;最后&lt;/h2&gt;

&lt;p&gt;写 lab3 的时候，对 lab2 的代码调整很大，发现了不少 bug 和逻辑不合理的地方，整体上对 raft 的理解更加深入了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MIT 6.824: lab2 Raft Consensus Algorithm Implementation</title>
      <link>http://wiesen.github.io/post/MIT-6.824-lab2-Raft-Consensus-Algorithm-Implementation/</link>
      <pubDate>Fri, 10 Jun 2016 21:32:46 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/MIT-6.824-lab2-Raft-Consensus-Algorithm-Implementation/</guid>
      <description>

&lt;p&gt;Raft 将一致性问题分为了三个相对独立的子问题，分别是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Leader election&lt;/strong&gt;：当前 leader 崩溃时，集群中必须选举出一个新的 leader；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Log replication&lt;/strong&gt;：leader 必须接受来自 clients 的 log entries，并且将其 replicate 到集群机器中，强制其余 logs 与其保持一致；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Safety&lt;/strong&gt;：Raft 中最关键的 safety property 是 State Machine Safety Property，亦即是，当任一机器 apply 了某一特定 log entry 到其 state machine 中，则其余服务器都不可能 apply 了一个 index 相同但 command 不同的 log。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;差不多依据上述划分，6.824 中 Raft 的实现指导逻辑还是挺清晰的，其中 safety property 由 Leader election 和 Log replication 共同承担，并且将 Persistence 作为最后一部分。实现过程主要分为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Leader Election and Heartbeats：首先令 Raft 能够在不存在故障的情景下选举出一个 leader，并且稳定保持状态；&lt;/li&gt;
&lt;li&gt;Log Replication：其次令 Raft 能够保持一个 consistent 并且 replicated 的 log；&lt;/li&gt;
&lt;li&gt;Persistence：最后令 Raft 能够持久化保存 persistent state，这样在重启后可以进行恢复。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中，本文主要参考 Raft paper，其中的 &lt;strong&gt;figure 2&lt;/strong&gt; 作用很大。本文实现&lt;strong&gt;大量依赖 channel 实现消息传递和线程同步&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Wiesen/MIT-6.824/blob/master/2016/raft/raft.go&#34;&gt;Code Link&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;leader-election-and-heartbeat&#34;&gt;Leader Election and Heartbeat&lt;/h2&gt;

&lt;p&gt;实现 Leader Election，主要是需要完成以下三个功能：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Role Transfer：state machine &amp;amp; election timer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先实现 Raft 的 sate machine，所有 server 都应当在初始化 Raft peer 时开启一个单独的线程来维护状态，令其在 Follower，Candidate，Leader 三个状态之间进行转换。&lt;/p&gt;

&lt;p&gt;有一点&lt;strong&gt;注意&lt;/strong&gt;的是，&lt;code&gt;nextIndex[]&lt;/code&gt; 和 &lt;code&gt;matchindex[]&lt;/code&gt; 需要在 election 后进行 reinitialize。&lt;/p&gt;

&lt;p&gt;func (rf *Raft) changeRole() {
        for true {
            switch rf.role {
            case Leader:
                for i := range rf.peers {
                    rf.nextIndex[i] = rf.logTable[len(rf.logTable)-1].Index + 1
                    rf.matchIndex[i] = 0
                }
                go rf.doHeartbeat()
                &amp;lt;-rf.chanRole
            case Candidate:
                chanQuitElect := make(chan bool)
                go rf.startElection(chanQuitElect)
                &amp;lt;-rf.chanRole
                close(chanQuitElect)
            case Follower:
                &amp;lt;-rf.chanRole
            }
        }
    }&lt;/p&gt;

&lt;p&gt;此外，定时器 election timer 的作用十分关键，所有 server 都应当在初始化 Raft peer 时开启一个单独的线程来维护 election timer。&lt;/p&gt;

&lt;p&gt;当 election timer 超时时，机器将会转换至 Candidate 状态。另外在以下三种情况下将会 reset 定时器：收到合法的 heartbeat message；投票给除自身以外的 candidate；自身启动election（本文视为转换为 Candidate 状态）。&lt;/p&gt;

&lt;p&gt;同样有一点需要注意，需要确保不同机器上的 timer 异步，也就是不会同时触发，否则所有机器都会自投票导致无法选举 leader。在 golang 中通过以时间作为种子投入到随机发生器中：&lt;code&gt;rand.Seed(time.Now().UnixNano())&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) startElectTimer() {
    floatInterval := int(RaftElectionTimeoutHigh - RaftElectionTimeoutLow)
    timeout := time.Duration(rand.Intn(floatInterval)) + RaftElectionTimeoutLow
    electTimer := time.NewTimer(timeout)
    for {
        select {
        case &amp;lt;- rf.chanHeartbeat: // received valid heartbeat message
            rf.resetElectTimer(electTimer)
        case &amp;lt;- rf.chanGrantVote: // voted for other server 
            rf.resetElectTimer(electTimer)
        case &amp;lt;-electTimer.C:      // fired election  
            rf.chanRole &amp;lt;- Candidate
            rf.resetElectTimer(electTimer)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;RequstVote RPC 的 sender 和 handler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;完成 Raft 的 sate machine后，开始实现 Raft 中的 RequestVote 操作，使得能够选举出一个 leader。&lt;/p&gt;

&lt;p&gt;机器处于 Candidate 状态时应当启动 election：&lt;code&gt;currentTerm++&lt;/code&gt; -&amp;gt; &lt;code&gt;votedFor = me&lt;/code&gt; -&amp;gt; &lt;code&gt;sendRequestVote()&lt;/code&gt;。其中 &lt;code&gt;sendRequestVote()&lt;/code&gt; 应当异步，也就是并发给其余机器发送 RequstVote。&lt;/p&gt;

&lt;p&gt;当出现以下情况，当前 election 过程终结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;获得大多数机器的投票 -&amp;gt; 转换为 Leader 状态；&lt;/li&gt;
&lt;li&gt;接受到的 reply 中 &lt;code&gt;term T &amp;gt; currentTerm&lt;/code&gt; -&amp;gt; 更新 &lt;code&gt;currentTerm&lt;/code&gt;，转换为 Follower 状态；&lt;/li&gt;
&lt;li&gt;election timer 超时 -&amp;gt; 终结当前 election，并且启动新一轮 election，保持 Candidate 状态；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个机器接收到 RequstVote RPC，需要决定是否投票：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果 RequstVote RPC 中的 &lt;code&gt;term T &amp;lt; currentTerm&lt;/code&gt;，直接返回 false 拒绝投票即可；&lt;/li&gt;
&lt;li&gt;如果 RequstVote RPC 中的 &lt;code&gt;term T &amp;gt; currentTerm&lt;/code&gt;，则需要更新 &lt;code&gt;currentTerm&lt;/code&gt;，转换为 Follower 状态；&lt;/li&gt;
&lt;li&gt;如果该机器在 &lt;code&gt;currentTerm&lt;/code&gt; 已经投票，则直接返回 false 拒绝投票；&lt;/li&gt;
&lt;li&gt;否则在满足 &amp;ldquo;Candidate&amp;rsquo;s log is at least as up-to-date as receiver&amp;rsquo;s log&amp;rdquo; 时返回 true 投票，并且 reset election timeout；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所谓 &lt;strong&gt;“up-to-date”&lt;/strong&gt; 简单来说就是：比较两个 log 中的最后一条 entry 的 &lt;code&gt;index&lt;/code&gt; 和 &lt;code&gt;term&lt;/code&gt;：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当两个 log 的最后一条 entry 的 term 不同，则 &lt;strong&gt;later&lt;/strong&gt; term is more up-to-date；&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当两个 log 的最后一条 entry 的 term 相同，则 whichever log is &lt;strong&gt;longer&lt;/strong&gt; is more up-to-date&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// RequestVote RPC handler.
func (rf *Raft) RequestVote(args RequestVoteArgs, reply *RequestVoteReply) {
  if rf.currentTerm &amp;gt; args.Term {
    reply.Term = rf.currentTerm
        reply.VoteGranted = false
    return
  }
  if rf.currentTerm &amp;lt; args.Term {
    rf.currentTerm = args.Term
    rf.votedFor = -1
    rf.chanRole &amp;lt;- Follower
  }
  reply.Term = args.Term
  if rf.votedFor != -1 &amp;amp;&amp;amp; rf.votedFor != args.CandidateId {
    reply.VoteGranted = false
  } else if rf.logTable[len(rf.logTable)-1].Term &amp;gt; args.LastLogTerm {
    reply.VoteGranted = false   //! different term
  } else if len(rf.logTable)-1 &amp;gt; args.LastLogIndex &amp;amp;&amp;amp; rf.logTable[len(rf.logTable)-1].Term == args.LastLogTerm { 
    reply.VoteGranted = false   //! same term but different index
  }else {
    reply.VoteGranted = true
    rf.votedFor = args.CandidateId
    rf.chanGrantVote &amp;lt;- true
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Heartbeat 的 sender 和 handler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最后实现 Raft 中的 Heartbeat 操作，能够令 Leader 稳定保持状态。&lt;/p&gt;

&lt;p&gt;机器处于 Leader 状态时应当启动 heartbeat，而其实际上就是不含 log entry 的 AppendEntries（只需要检测某一机器的 log 是否最新）。&lt;/p&gt;

&lt;p&gt;其中 &lt;code&gt;sendHeartbeat()&lt;/code&gt; 应当异步，也就是并发给其余机器发送 heartbeat。每一个 heartbeat 线程利用 timer 来周期性地触发操作。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) sendHeartbeat(server int) {
    for rf.getRole() == Leader {
                rf.doAppendEntries(server)  // later explain in Log Replication
                heartbeatTimer.Reset(RaftHeartbeatPeriod)
                &amp;lt;-heartbeatTimer.C
        }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一个机器接收到不含 log entry 的 AppendEntries RPC（也就是 heartbeat）时，需要决定是否更新自身的 term 和 leaderId：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果 AppendEntries RPC 中的 &lt;code&gt;term T &amp;lt; currentTerm&lt;/code&gt;，则 reply 中返回 &lt;code&gt;currentTerm&lt;/code&gt; 让发送方更新；&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果 RequstVote RPC 中的 &lt;code&gt;term T &amp;gt; currentTerm&lt;/code&gt;，则需要更新 &lt;code&gt;currentTerm&lt;/code&gt; 和 &lt;code&gt;leaderId&lt;/code&gt;，转换为 Follower 状态，并且 reset election timeout；&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// temporary AppendEntries RPC handler.
func (rf *Raft) AppendEntries(args AppendEntriesArgs, reply *AppendEntriesReply) {
    if args.Term &amp;lt; rf.currentTerm {
        reply.Term = rf.currentTerm
        reply.Success = false
        return
    }
    //! update current term and only one leader granted in one term
    if rf.currentTerm &amp;lt; args.Term {
        rf.currentTerm = args.Term
        rf.votedFor = -1
        rf.leaderId = args.LeaderId
        rf.chanRole &amp;lt;- Follower
    }
    rf.chanHeartbeat &amp;lt;- true
    reply.Term = args.Term
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;log-replication&#34;&gt;Log Replication&lt;/h2&gt;

&lt;p&gt;完成了 Leader election 后，下一步是令 Raft 保持一个 consistent 并且 replicated 的 log。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;AppendEntries RPC sender&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在 Raft 中，只有 leader 允许添加 log，并且通过发送含有 log 的 AppendEntries RPC 给其余机器令其 log 保持一致。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) Replica() {
// replica log
for server := range rf.peers {
    if server != rf.me {
        go rf.doAppendEntries(server)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来主要是 &lt;code&gt;doAppendEntries(server int)&lt;/code&gt; 的实现细节。&lt;/p&gt;

&lt;p&gt;当 Leader 的 log 比某 server 长时，亦即是 &lt;code&gt;rf.nextIndex[server] &amp;lt; len(rf.logTable)&lt;/code&gt;，则需要发送 entry&lt;/p&gt;

&lt;p&gt;有一点要&lt;strong&gt;注意&lt;/strong&gt;的是：Leader 在对某 server 进行上述的连续发送时间或者等待 reply 的时间可能会大于 heartbeat timeout，因此触发 AppendEntries RPC。然而 Leader 本身正在等待 reply，这时候重复发送是多余的。&lt;/p&gt;

&lt;p&gt;本文检测 Leader 是否在向某 server 发送 AppendEntries RPC，若是则直接退出不再重复操作：这里设计为 Leader 为每一 server 维护一个带有&lt;strong&gt;一个缓存&lt;/strong&gt;的管道，这样某 server 进行 AppendEntries RPC 前可以确认是否正在处理。&lt;/p&gt;

&lt;p&gt;最后如果 RPC failed 则直接退出，否则收到 AppendEntries RPC 的 reply 时：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先判断是否 &lt;code&gt;reply.Term &amp;gt; args.Term&lt;/code&gt;，若是则 Leader 需要更新自身 currentTerm，并且转换为 Follower 状态。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;若 &lt;code&gt;reply.Success&lt;/code&gt; 会表明达成一致，更新 &lt;code&gt;rf.matchIndex[server]&lt;/code&gt; 和 &lt;code&gt;rf.nextIndex[server]&lt;/code&gt;；否则仅更新 &lt;code&gt;rf.nextIndex[server]&lt;/code&gt;（这里涉及到 3 中的优化）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) doAppendEntries(server int) {
    //! make a lock for every follower to serialize
    select {
    case &amp;lt;- rf.chanAppend[server]:
    default: return
    }
    defer func() {rf.chanAppend[server] &amp;lt;- true}()

    for rf.getRole() == Leader {
        rf.mu.Lock()
        var args AppendEntriesArgs
        ...             // set variable value
        if rf.nextIndex[server] &amp;lt; len(rf.logTable) {
            args.Entry = rf.logTable[rf.nextIndex[server]:]
        }
        rf.mu.Unlock()

        var reply AppendEntriesReply
        if rf.sendAppendEntries(server, args, &amp;amp;reply) {
            if rf.role != Leader {
                return
            }
            if args.Term != rf.currentTerm || reply.Term &amp;gt; args.Term {
                if reply.Term &amp;gt; args.Term {
                    ... // update term and role
                }
                return
            }
            if reply.Success {
                rf.matchIndex[server] = reply.NextIndex - 1
                rf.nextIndex[server] = reply.NextIndex
            } else {
                rf.nextIndex[server] = reply.NextIndex
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;AppendEntries RPC handler&lt;/strong&gt; (2016.8.5 Update)&lt;/p&gt;

&lt;p&gt;一个机器接收到含有 log entry 的 AppendEntries RPC，前一部分跟处理 heartbeat 一样，剩下的部分则是决定是否更新自身的 log。根据 Raft paper 中的 figure 2 按部就班实现就好了。&lt;/p&gt;

&lt;p&gt;Update：处理 log entries array 还是需要注意一下：首先决定是否更新 log table，当满足条件决定更新后，主要存在三种更新情况：（1）更新旧 index；（2）更新旧 index，且添加新 index；（3）仅添加新 index。（如下图）&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/raft-appendentries.bmp&#34; alt=&#34;raft-appendentries&#34; /&gt;&lt;/p&gt;

&lt;p&gt;本文方法是：首先记录下当前开始处理的 &lt;code&gt;basicIndex := args.PrevLogIndex + 1&lt;/code&gt;（即 &lt;code&gt;args.Entry&lt;/code&gt; 中的起始 index），然后遍历 &lt;code&gt;args.Entry&lt;/code&gt;，一旦 index 已达 logTable 末端或者某个 entry 的 term 不匹配，则清除 logTable 中当前及后续的 entry，并且将 &lt;code&gt;args.Entry&lt;/code&gt; 的当前及后续 entry 添加到 logTable中。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;AppendEntries RPC optimization&lt;/strong&gt; (2016.8.5 Update)&lt;/p&gt;

&lt;p&gt;这一部分主要是优化 AppendEntries RPC，当发生拒绝 append 时减少 master 需要发送 RPC 的次数。虽然 Raft paper 中怀疑这个优化操作是否有必要，但 lab2 中有些 unreliable test case 就需要你实现这个优化操作…&lt;/p&gt;

&lt;p&gt;首先需要在 struct AppendEntriesReply 中添加两个数据：&lt;code&gt;NextIndex int&lt;/code&gt;,  &lt;code&gt;FailTerm int&lt;/code&gt;，分别用于指示 conflicting entry 所在 term，以及在该 term 中存储的第一个 entry 的 index；&lt;/p&gt;

&lt;p&gt;在 handler 的优化如下：如果 log unmatched，存在两种情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;len(rf.logTable) &amp;lt;= args.PrevLogIndex&lt;/code&gt;：则直接返回 &lt;code&gt;NextIndex = len(rf.logTable)&lt;/code&gt; 即可；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rf.logTable[args.PrevLogIndex].Term != args.PrevLogTerm&lt;/code&gt;：首先记录 &lt;code&gt;FailTerm&lt;/code&gt;，然后从当前 conflicting entry 开始向前扫描，直到 index 为 0 或者 term 不匹配，然后记录下该 term 的第一个 index；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在 sender 的优化如下：当 append 失败时，如果 &lt;code&gt;NextIndex &amp;gt; matchIndex[server]&lt;/code&gt;，则 &lt;code&gt;nextIndex[server]&lt;/code&gt; 直接退至 &lt;code&gt;NextIndex&lt;/code&gt;，减少了需要尝试 append 的 RPC 次数；否则 &lt;code&gt;nextIndex[server]&lt;/code&gt; 退回到 &lt;code&gt;matchIndex[server] + 1&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;STEP 4. Apply committed entries to local service replica&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于 Leader 而言，需要不断检测当前 term 的 log entry 的 replica 操作是否完成，然后进行 commit 操作。&lt;/p&gt;

&lt;p&gt;当超过半数的机器已经完成 replica 操作，则 Leader 认为该条 log entry 可以 commit。&lt;/p&gt;

&lt;p&gt;一旦当前 term 的某条 log entry L 是通过上述方式 commit 的，则根据 Raft 的 &lt;strong&gt;Log Matching Property&lt;/strong&gt;，Leader 可以 commit 先于 L 添加到 log 的所有 entry。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) updateLeaderCommit() {
    rf.mu.Lock()
    defer rf.mu.Unlock()
    defer rf.persist()
    oldIndex := rf.commitIndex
    newIndex := oldIndex
    for i := len(rf.logTable)-1; i&amp;gt;oldIndex &amp;amp;&amp;amp; rf.logTable[i].Term==rf.getCurrentTerm(); i-- {
        countServer := 1
        for server := range rf.peers {
            if server != rf.me &amp;amp;&amp;amp; rf.matchIndex[server] &amp;gt;= i {
                countServer++
            }
        }
        if countServer &amp;gt; len(rf.peers) / 2 {
            newIndex = i
            break
        }
    }
    if oldIndex == newIndex {
        return
    }
    rf.commitIndex = newIndex

    //! update the log added in previous term
    for i := oldIndex + 1; i &amp;lt;= newIndex; i++ {
        rf.chanCommitted &amp;lt;- ApplyMsg{Index:i, Command:rf.logTable[i].Command}
        rf.lastApplied = i
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于 Follower 而言，则：&lt;code&gt;commitIndex = min(leaderCommit, index of last new entry)&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;persistence&#34;&gt;Persistence&lt;/h2&gt;

&lt;p&gt;最后一步是持久化保存 persistent state，不过在 lab2 仅是通过 &lt;code&gt;persister&lt;/code&gt; object 来保存，并没有真正使用到磁盘。实现了这一部分后可以稳定地 pass 掉关于 Persist 的 test case。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Read persist&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在 Make Raft peer 时读取 persister。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Write persist&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;修改了 Raft 的 persistent state 后应当及时写至 persister，主要是在以下几个地方插入 write：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动了 election 修改了自身的 persistent state后；&lt;/li&gt;
&lt;li&gt;受到了 RequestVote RPC 和 AppendEntries RPC 的 reply，得知需要更新自身的 persistent state 后；&lt;/li&gt;
&lt;li&gt;RequestVote RPC handler 和 AppendEntries RPC handler 处理完毕后；&lt;/li&gt;
&lt;li&gt;Leader 收到 client 的请求命令，添加到自身的 log 后。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;defect&#34;&gt;Defect&lt;/h2&gt;

&lt;p&gt;本文还有些不足，有待后续优化。主要是&lt;strong&gt;不能稳定地&lt;/strong&gt; pass &lt;code&gt;TestUnreliableAgree()&lt;/code&gt; + &lt;strong&gt;不能&lt;/strong&gt; pass &lt;code&gt;TestFigure8Unreliable()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To Be Continue&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;2016-8-11-update&#34;&gt;2016-8-11 Update&lt;/h2&gt;

&lt;p&gt;最近几天 debug 了之前的代码，发现了若干个问题。目前的代码实现已经&lt;strong&gt;比较稳定&lt;/strong&gt;地 pass 所有的 test case，上面的代码段也已经修改了。但仍然存在一个 bug: 在过 TestUnreliableAgree() 时 fail to reach agreement。这个 bug 的触发几率很低，还没想明白哪里出问题。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;LEADER ELECTION: Role Transfer (state machine)&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;之前实现 server state machine 的方法是利用 channel 来进行状态修改操作，并且会新开一个 goroutine 进行该状态死循环，而没有其他状态的处理逻辑。本文由一个 goroutine 阻塞读取该 channel，从而处理 server 的状态转换。然而，channel 同步是存在延时的，只有在当前 goroutine 被挂起或者休眠等时，才会转去处理。&lt;/p&gt;

&lt;p&gt;这样的方法存在一个 bug：新 Leader 产生后，旧 Leader 收到消息应该更新自身的 term 并且转换为 Follower；然而由于 channel 同步并非立即执行，旧 Leader 在自身状态被重新赋值前仍然会执行 Leader 的代码；这时候就会出现两个 Leader 同时处理 RPC。&lt;/p&gt;

&lt;p&gt;因此，修改的内容是：去掉 channel 同步方法，当需要进行状态转换时，立即修改 server 的状态，终止该 server 当前状态的执行。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;LOG REPLICATION: AppendEntries RPC&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;之前不能 pass &lt;code&gt;TestUnreliableAgree()&lt;/code&gt; 和 &lt;code&gt;TestFigure8Unreliable()&lt;/code&gt; 时丝毫没有提示，只能等程序运行时间过长然后被杀死。后来思考了一下问题原因：&lt;strong&gt;程序运行过慢，跟不上 test case 要求的速度，所以后续的测试代码也根本没有执行&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;然后发现程序执行慢的原因是：Leader 发送 AppendEntries RPC 每次仅携带一条 log entry，导致 server 无法快速 catch up。所以修改的主要内容就是：AppendEntries RPC 每次携带从 &lt;code&gt;nextIndex&lt;/code&gt; 直到最新的 log entries。&lt;/p&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://www.douban.com/note/549229678/&#34;&gt;MIT 6.824 Week 3 notes&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Flat Datacenter Storage Paper Review</title>
      <link>http://wiesen.github.io/post/Flat-Datacenter-Storage-Paper-Review/</link>
      <pubDate>Wed, 30 Mar 2016 21:33:37 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/Flat-Datacenter-Storage-Paper-Review/</guid>
      <description>

&lt;p&gt;A review for paper Nightingale E B, Elson J, Fan J, et al. Flat datacenter storage[C]//Presented as part of the 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12). 2012: 1-15.&lt;/p&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;What is FDS?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Flat Datacenter Storage (FDS) is a high-performance, fault-tolerant, large-scale, &lt;strong&gt;locality-oblivious&lt;/strong&gt; blob store.&lt;/li&gt;
&lt;li&gt;Using a novel combination of &lt;strong&gt;full bisection bandwidth networks&lt;/strong&gt;, &lt;strong&gt;data and metadata striping&lt;/strong&gt;, and** flow control**, FDS multiplexes an application’s large-scale I/O across the available throughput and latency budget of every disk in a cluster.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How is the Performance?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2 GByte/sec per client.&lt;/li&gt;
&lt;li&gt;Recover from lost disk (92 GB) in 6.2 seconds.&lt;/li&gt;
&lt;li&gt;It sets the world-record for disk-to-disk sorting in 2012 for MinuteSort: 1,033 disks and 256 computers (136 tract servers, 120 clients), 1,401 Gbyte in 59.4s.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;architecture&#34;&gt;Architecture&lt;/h1&gt;

&lt;p&gt;High-level design &amp;ndash; a common pattern&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/fds-flat.png&#34; alt=&#34;comparison&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Right distributed model - GFS &amp;amp; HDFS: Data is either on a local disk or a remote disk.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Move the computation to data. Location awareness adds &lt;strong&gt;complexity&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Why move? Because remote data access is slow.&lt;/li&gt;
&lt;li&gt;Why slow? Because the network is oversubscribed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Left distributed model &amp;ndash; FDS: Object storage assuming no oversubscription. Data is &lt;em&gt;all&lt;/em&gt; remote.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Separates the storage from computation.&lt;/li&gt;
&lt;li&gt;No local vs. remote disk distinction&lt;/li&gt;
&lt;li&gt;simpler work schedulers&lt;/li&gt;
&lt;li&gt;simpler programming models&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/fds-architectures.png&#34; alt=&#34;architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Above it&amp;rsquo;s the architecture of FDS:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lots of clients, and lots of storage servers (&amp;ldquo;tractservers&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;Partition the data, and master (&amp;ldquo;metadata server&amp;rdquo;) controls partitioning&lt;/li&gt;
&lt;li&gt;Replica groups for reliability&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;deisign-overview&#34;&gt;Deisign Overview&lt;/h1&gt;

&lt;h2 id=&#34;how-to-store-data-blobs-and-tracts&#34;&gt;How to store data? &amp;ndash; Blobs and Tracts&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Data is logically stored in blobs.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A blob is a byte sequence named with a 128-bit GUID.&lt;/li&gt;
&lt;li&gt;Blobs can be &lt;em&gt;any length&lt;/em&gt; up to the system’s storage capacity.&lt;/li&gt;
&lt;li&gt;Blobs are divided into &lt;strong&gt;tracts&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Tracts are the units responsible for read and write&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Tracts are &lt;em&gt;sized&lt;/em&gt; such that random and sequential access achieves nearly the same throughput.&lt;/li&gt;
&lt;li&gt;The tract size is set when the cluster is created based upon cluster hardware.(64kb~8MB)&lt;/li&gt;
&lt;li&gt;All tracts’ metadata is &lt;strong&gt;cached in memory&lt;/strong&gt;, eliminating many disk accesses.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Every disk is managed by a process called a tractserver:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Services read and write requests from clients.&lt;/li&gt;
&lt;li&gt;Lay out tracts &lt;strong&gt;directly to disk by using the raw disk interface&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Provides API, and the API features are follow:

&lt;ul&gt;
&lt;li&gt;Tract reads are not guaranteed to arrive in order of issue. Writes are not guaranteed to be committed in   order of issue.&lt;/li&gt;
&lt;li&gt;Tractserver writes are &lt;em&gt;atomic&lt;/em&gt;: a write is either committed or failed completely.&lt;/li&gt;
&lt;li&gt;Calls are &lt;em&gt;asynchronous&lt;/em&gt;: using callback, allows deep pipelining to achieve good performance.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Weak&lt;/em&gt; consistency to clients&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;how-to-organize-and-manage-metadata-deterministic-data-placement&#34;&gt;How to organize and manage metadata? &amp;ndash; Deterministic data placement&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Many systems solve this problem using a metadata server that stores the location of data blocks.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Advantage: allowing maximum flexibility of data placement and visibility into the system’s state.&lt;/li&gt;
&lt;li&gt;Drawbacks: the metadata server is a central point of failure, usually implemented as a replicated state machine.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;FDS uses a metadata server, but it&amp;rsquo;s role is simple and limited:  &lt;strong&gt;tract locator table&lt;/strong&gt; (&lt;strong&gt;TLT&lt;/strong&gt;):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;collect a list of the system’s active tractservers and distribute it to clients.&lt;/li&gt;
&lt;li&gt;With &lt;em&gt;k-way&lt;/em&gt; replication, each entry has the address of &lt;em&gt;k&lt;/em&gt; tractservers.&lt;/li&gt;
&lt;li&gt;Weighted by disk speed&lt;/li&gt;
&lt;li&gt;Only update when cluster changes&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Compute a tract index to read or write, which is designed to both be deterministic and produce uniform disk utilization: &lt;em&gt;Tract_Locator&lt;/em&gt; = TLT[(Hash(&lt;em&gt;GUID&lt;/em&gt;) + &lt;em&gt;Tract&lt;/em&gt;) % len(TLT)]&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hash(&lt;em&gt;GUID&lt;/em&gt;)&lt;/strong&gt;: Randomize blob&amp;rsquo;s tractserver, even if GUIDs aren&amp;rsquo;t random (uses SHA-1)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Tract&lt;/em&gt;&lt;/strong&gt;: adds tract number outside the hash, so large blobs use all TLT entries uniformly&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Compute a tract index for Blob metadata, which enable to distribute Blob metadata: &lt;em&gt;Tract_Locator&lt;/em&gt; = TLT[(Hash(&lt;em&gt;GUID&lt;/em&gt;) - 1) % len(TLT)]&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The metadata server isn&amp;rsquo;t a single point failure.&lt;/li&gt;
&lt;li&gt;Parallelized operation can be servied in parallel by independent tractservers.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;To summarize, FDS metadata scheme has following properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The metadata server is in the critical path &lt;em&gt;only&lt;/em&gt; when a client process starts.&lt;/li&gt;
&lt;li&gt;The TLT can be &lt;em&gt;cached long-term&lt;/em&gt;, eliminating all traffic to the metadata server under normal conditions.&lt;/li&gt;
&lt;li&gt;TLT contains random permutations of the list of tractservers, which make sequential reads and writes parallel.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;what-kind-of-application-will-will-not-benefic-from-fds-dynamic-work-allocation&#34;&gt;What kind of application will /will not benefic from FDS? &amp;ndash; Dynamic Work Allocation&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Since &lt;strong&gt;storage and compute are no longer colocated&lt;/strong&gt;, the assignment of work to worker can be done &lt;em&gt;dynamically&lt;/em&gt; at fine granularity &lt;em&gt;during&lt;/em&gt; task execution, which enables FDS to &lt;strong&gt;mitigate stragglers&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;best practice&lt;/strong&gt; for FDS applications is to centrally (or, at large scale, hierarchically) give small units of work to each worker as it nears completion of its previous unit.&lt;/li&gt;
&lt;li&gt;Such a scheme is &lt;strong&gt;not practical&lt;/strong&gt; in systems where the assignment of work to workers is fixed in advance by the requirement that data be resident at a particular worker before the job begins.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;replication-and-failure-recovery&#34;&gt;Replication and Failure Recovery&lt;/h1&gt;

&lt;h2 id=&#34;replication&#34;&gt;Replication&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Serialized Blob operation &lt;em&gt;Create&lt;/em&gt;, &lt;em&gt;Delete&lt;/em&gt;, &lt;em&gt;Extend&lt;/em&gt;: client writes to primary, primary executes a &lt;strong&gt;two-phase commit&lt;/strong&gt; with replicas.&lt;/li&gt;
&lt;li&gt;Write to &lt;em&gt;all&lt;/em&gt; replicas, read from &lt;em&gt;random&lt;/em&gt; replica&lt;/li&gt;
&lt;li&gt;Supports per-blob &lt;strong&gt;variable replication&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;failure-recovery&#34;&gt;Failure recovery&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;each ertry in TLT has a &lt;strong&gt;version number&lt;/strong&gt; to control update, and &lt;em&gt;all&lt;/em&gt; operations as well.&lt;/li&gt;
&lt;li&gt;Transient failures: &lt;strong&gt;partial failure recovery&lt;/strong&gt; that complete failure recovery or use other replicas to recover the writes that the returning tractserver missed.&lt;/li&gt;
&lt;li&gt;Cascading tractserver failures: fill more slots in the TLT&lt;/li&gt;
&lt;li&gt;Concurrent tractserver failures: detected as missing TLT entries, and execute normal failure recovery protocol.&lt;/li&gt;
&lt;li&gt;Metadata server failures: using Paxos leader election&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;replicated-data-layout&#34;&gt;Replicated data layout&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;The selection of which k disks appear has an important impact on both durability and recovery speed&lt;/li&gt;
&lt;li&gt;A better TLT has &lt;em&gt;O(n^2)&lt;/em&gt; entries, so each possible pair of disks appears in anentry of the TLT.

&lt;ul&gt;
&lt;li&gt;First, performance during recovery involves &lt;em&gt;every disk&lt;/em&gt; in the cluster.&lt;/li&gt;
&lt;li&gt;a triple disk failure within the recovery window has only about a &lt;em&gt;2/n&lt;/em&gt; chance of causing permanent data loss.&lt;/li&gt;
&lt;li&gt;adding more replicas decreases the probability of data loss.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cluster-growth&#34;&gt;Cluster growth&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Rebalances the assignment of TLT entries so that both existing data and new workloads are uniformly distributed.&lt;/li&gt;
&lt;li&gt;These assignments happen in two phases (&lt;code&gt;pending&lt;/code&gt; and &lt;code&gt;commits&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;If a new tractserver fails while its TLT entries are pending, increments the TLT entry version and expunges it.&lt;/li&gt;
&lt;li&gt;new tractservers must read from the existing tractserver with a superset of the data required.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;networking&#34;&gt;Networking&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Network bandwidth = disk bandwidth&lt;/li&gt;
&lt;li&gt;Full bisection bandwidth is stochastic&lt;/li&gt;
&lt;li&gt;Short flows good for ECMP&lt;/li&gt;
&lt;li&gt;TCP &lt;em&gt;hates&lt;/em&gt; short flows, but RTS/CTS to mitigate incast&lt;/li&gt;
&lt;li&gt;FDS works &lt;em&gt;great&lt;/em&gt; for Blob Storate on CLOS networks.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Reference：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.binospace.com/index.php/flat-datacenter-storage-system-analysis/&#34;&gt;Flat DataCenter Storage之系统分析&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://cs.stackexchange.com/questions/23163/how-does-fds-flat-datacenter-storage-make-optimizations-around-locality-unnece&#34;&gt;How does FDS (flat datacenter storage) make optimizations around locality unnecessary?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=YbOjxCxtMpU&#34;&gt;Youtube video&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Chain Replication Paper Review</title>
      <link>http://wiesen.github.io/post/Chain-Replication-Paper-Review/</link>
      <pubDate>Sat, 19 Mar 2016 21:33:09 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/Chain-Replication-Paper-Review/</guid>
      <description>

&lt;p&gt;本文是读完 Van Renesse R, Schneider F B. Chain Replication for Supporting High Throughput and Availability[C]//OSDI. 2004. 的总结。&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Chain replication is a new approach to coordinating clusters of fail-stop storage servers.&lt;/p&gt;

&lt;p&gt;Chain replication 采用 ROWAA (read one, write all available) 方法, 具有良好的 Scalability.&lt;/p&gt;

&lt;p&gt;该方法目的是, &lt;strong&gt;不以牺牲强一致性为代价来实现高吞吐和高可用&lt;/strong&gt;, 从而提供分布式存储服务.&lt;/p&gt;

&lt;h2 id=&#34;a-storage-service-interface&#34;&gt;A Storage Service Interface&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Clients&lt;/strong&gt; 发送 query 或 update 操作 request&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The storage service&lt;/strong&gt; 为每个 request 生成 reply 发送会 client 告知其已经接收或已经处理完成, 从而 client 可以得知某 request 是否接收成功以及是否处理完成.&lt;/p&gt;

&lt;p&gt;Client request type:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;query(objId, opts) -&amp;gt; value&lt;/code&gt;: retrieve current value of &lt;em&gt;opts&lt;/em&gt; of &lt;em&gt;objId&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;update(objId, newVal, opts) -&amp;gt; value&lt;/code&gt;: update &lt;em&gt;opts&lt;/em&gt; of &lt;em&gt;objId&lt;/em&gt; with &lt;em&gt;newVal&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Client&amp;rsquo;s view of an object:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;State is:
    Hist[objId]: history of all updates to objId
    Pending[objId]: set of pending requests for objId
Transitions are:
    T1: Client request r arrives: 
        Pending[objId] += {r}
    // 一个 client request 接收失败 = server 忽略了该 client request
    T2: Client request r ∈ Pending[objId] ignored: 
        Pending[objId] -= {r}
    T3: Client request r ∈ Pending[objId] processed: 
        Pending[objId] -= {r}
        if r = query(objId, opts) then 
            reply according options opts based on Hist[objId]
        else if r = update(objId, newVal, opts) then
            Hist[objId] := Hist[objId] · r
            reply according options opts based on Hist[objId]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;chain-replication-protocol&#34;&gt;Chain Replication Protocol&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;1. Assumptions: 所有服务器均假设为 fail-stop&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;each server halts in response to a failure&lt;/li&gt;
&lt;li&gt;a server’s halted state can be detected by the environment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2. Protocol Details&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在 chain replication 中, 所有 servers 根据 &lt;em&gt;objID&lt;/em&gt; 线性排列从而组成一个链表.
&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/the%20chain.png&#34; width=&#34;400&#34;/&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;所有 update 操作由 HEAD 结点接收并开始处理, 然后按照FIFO顺序向链表中的下一个节点传递, 直到该 update 操作被 TAIL 节点处理.&lt;/li&gt;
&lt;li&gt;所有 query 操作由 TAIL 结点接收并处理.&lt;/li&gt;
&lt;li&gt;所有 query 操作 / update 操作的确认由 TAIL 结点处理 (即发送 reply 给 client).
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3. Coping with Server Failures&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;论文中构建一个 &lt;em&gt;master&lt;/em&gt; server, 其主要功能如下 (为区分本文将其余负责数据存储的 server 称为 &lt;em&gt;data&lt;/em&gt; server):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;检测其余 &lt;em&gt;data&lt;/em&gt; servers 的失败&lt;/li&gt;
&lt;li&gt;在链表新增或删除节点时, 通知 &lt;em&gt;data&lt;/em&gt; servers 更新 predecessor 及 successor&lt;/li&gt;
&lt;li&gt;告知 client 链表的 HEAD 节点和 TAIL 节点&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;论文中假设 &lt;em&gt;master&lt;/em&gt; server 永不崩溃。而实际上该论文的 prototype 利用 Paxos 协调 &lt;em&gt;master&lt;/em&gt; server 的各个 replicas 从而 behave in aggregate like a single process that does not fail, 以此避免单点故障.&lt;/p&gt;

&lt;p&gt;下面仅讨论 &lt;em&gt;data&lt;/em&gt; server 故障, 即如何在链表中的节点出现故障时保证存储服务的强一致性.主要分为以下头节点, 尾节点和中间节点三种情况.&lt;/p&gt;

&lt;p&gt;论文中阐述了两个性质:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Update Propagation Invariant (更新传递不变性)&lt;/strong&gt;. 意即对于编号 &lt;em&gt;i&lt;/em&gt; 和 &lt;em&gt;j&lt;/em&gt;, 若有: &lt;img src=&#34;http://latex.codecogs.com/gif.latex?i%20%5Cle%20j&#34; alt=&#34;fomula&#34; /&gt; (例如 &lt;em&gt;i&lt;/em&gt; 是 &lt;em&gt;j&lt;/em&gt; 的 predecessor), 则有:  successor 的 update 操作序列 是 predecessor 的前缀 —— &lt;img src=&#34;http://latex.codecogs.com/gif.latex?Hist%5Ej_%7BobjID%7D%20%5Cpreceq%20Hist%5Ei_%7BobjID%7D&#34; alt=&#34;fomula&#34; /&gt; (该性质根据链表节点间 update 操作由 FIFO 传递得出)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inprocess Requests Invariant (上下文请求不变性)&lt;/strong&gt;. 每个 server &lt;em&gt;i&lt;/em&gt; 维护一个列表 &lt;img src=&#34;http://www.forkosh.com/mathtex.cgi?Sent_i}&#34;&gt;, 其中存储着 server &lt;em&gt;i&lt;/em&gt; 已经处理并传递给 successor 节点但可能未被 tail 节点处理的 update requests. 当 tail 节点处理了一个 update request &lt;em&gt;r&lt;/em&gt; 后会发送确认 &lt;em&gt;ack&amp;reg;&lt;/em&gt; 给 predecessor, server &lt;em&gt;i&lt;/em&gt; 接收 &lt;em&gt;ack&amp;reg;&lt;/em&gt; 后将 &lt;em&gt;r&lt;/em&gt; 从 &lt;img src=&#34;http://www.forkosh.com/mathtex.cgi?Sent_i}&#34;&gt; 中删除, 然后依次向前传递. 据此, 若有: &lt;img src=&#34;http://latex.codecogs.com/gif.latex?Hist%7B%5Ei_%7BobjID%7D%7D%20%3D%20Hist%7B%5Ej_%7BobjID%7D%7D%20%5Coplus%20Sent_i&#34; alt=&#34;fomula&#34; /&gt; (根据 tail 节点接收到的 request 必定已被其所有 predecessors 接收到这一事实得出)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Head 节点故障停止&lt;/strong&gt;: 将 Head 节点从链表中移除, 其 successor 节点称为新的 Head 节点. 旧 Head 节点已经传递的 update 操作继续传递, 而丢失的 update 操作可视为 server 忽略了该 update (如前所述等同于server 接收该 client request 失败), 因此对应的 client request 将无法接收到 reply, 此时 client 会 resend request. 不影响存储服务的强一致性.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tail 节点故障停止&lt;/strong&gt;: 将 Tail 节点从链表中移除, 其前继 Tail- 节点称为新的 Tail 节点. 由于 &lt;img src=&#34;http://latex.codecogs.com/gif.latex?Tail%5E-%20%3C%20Tail%20%5Cto%20Hist%7B%5E%7Btail%7D_%7BobjID%7D%7D%20%5Cpreceq%20Hist%7B%5E%7BTail%5E-%7D_%7BobjID%7D%7D&#34; alt=&#34;fomula&#34; /&gt;, 从用户的角度看即数据变新变多了, 因此并不影响存储服务的读一致性.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中间节点故障停止&lt;/strong&gt;: 将故障节点 S 从链表中移除, 然后 &lt;em&gt;master&lt;/em&gt; server 首先通知故障节点的后继 S+ 节点新的链表配置, 然后通知前继 S- 节点连接后继 S+ 节点并要求其处理 &lt;img src=&#34;http://www.forkosh.com/mathtex.cgi?Sent^-}&#34;&gt; 中的 update request, 后序 update 操作继续传递下去, 因此也不影响存储服务的强一致性.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;扩展链表&lt;/strong&gt;: 当越来越多故障节点被移除, 链表将会缩短, 同时容错性下降.因此当链表变短时应当向链表中添加新的 servers. 理论上可以在链表的任何位置添加新 server, 但最简单的方法是在结尾添加 T+ 节点. 首先 T+ 通过复制 &lt;img src=&#34;http://www.forkosh.com/mathtex.cgi? Hist{^T_{objID}}&#34;&gt; 到 &lt;img src=&#34;http://www.forkosh.com/mathtex.cgi? Hist{^{T^+}_{objID}}&#34;&gt; 完成初始化, 然后 T+ 节点一边处理由 T 节点 forward 过来的 query request 一边处理 &lt;img src=&#34;http://www.forkosh.com/mathtex.cgi?Sent^T}&#34;&gt;, 最后 T+ 正式作为新的 tail 节点.&lt;/p&gt;

&lt;h2 id=&#34;comparision-to-primary-backup-protocols&#34;&gt;Comparision to Primary/Backup Protocols&lt;/h2&gt;

&lt;p&gt;Chain replication 是 primary/backup 方法的一种改进, 实际上是一种副本管理的状态机方法.&lt;/p&gt;

&lt;p&gt;在 primary/backup 方法中, 有一个 &lt;em&gt;primary&lt;/em&gt; server, 负责序列化 client requests (从而保证强一致性), 然后将序列化的 client requests 或 resulting updates 分散发送到各个 &lt;em&gt;backup&lt;/em&gt; servers, 等待接收非故障 &lt;em&gt;backups&lt;/em&gt; 的确认信息, 最后发送 reply 给 client. 当 &lt;em&gt;primary&lt;/em&gt; server 故障停止, 其中一个 &lt;em&gt;backup&lt;/em&gt; server 将提升为 &lt;em&gt;primary&lt;/em&gt; server.&lt;/p&gt;

&lt;p&gt;相比 primary/backup 方法, Chain replication 的不同如下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;client requests 由两个 replicas 处理, 即 head 节点负责序列化处理 update request, tail 节点并行处理 query requests, 降低了 query requests 的 latency.&lt;/li&gt;
&lt;li&gt;Chain replication 只能串行传递 update requests, 因此发送 reply 的 latency 与 the sum of server latencies 成比例.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当出现 server 故障停止时, Chain replication 和 primary/backup 方法的主要时延都是检测 server failure, 其次是 recovery.&lt;/p&gt;

&lt;h2 id=&#34;simulation-experiments&#34;&gt;Simulation Experiments&lt;/h2&gt;

&lt;p&gt;论文在四种情况下进行实验:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Single Chain, No Failures&lt;/li&gt;
&lt;li&gt;Multiple Chains, No Failures&lt;/li&gt;
&lt;li&gt;Effects of Failures on Throughput&lt;/li&gt;
&lt;li&gt;Large Scale Replication of Critical Data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;additional-application&#34;&gt;Additional: Application&lt;/h2&gt;

&lt;p&gt;在 &lt;a href=&#34;https://www.usenix.org/legacy/events/usenix09/tech/full_papers/terrace/terrace.pdf&#34;&gt;CRAQ&lt;/a&gt; 论文中介绍了基于 chain replication 的 CRAQ 系统, 该系统扩展了 chain replication protocol, 使链表上的所有节点均可处理 query 操作, 提高系统的吞吐, 同时仍然提供强一致性保证.&lt;/p&gt;

&lt;p&gt;微软云计算平台 &lt;a href=&#34;http://sigops.org/sosp/sosp11/current/2011-Cascais/printable/11-calder.pdf&#34;&gt;Windows Azure&lt;/a&gt;、&lt;a href=&#34;http://sigops.org/sosp/sosp11/current/2011-Cascais/printable/11-calder.pdf&#34;&gt;FDS&lt;/a&gt; 都使用 chain replication protocol 提供强一致性保证.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nEbD-qutsKo&#34;&gt;https://www.youtube.com/watch?v=nEbD-qutsKo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/yfkiss/article/details/13772669&#34;&gt;http://blog.csdn.net/yfkiss/article/details/13772669&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.xiaoheshang.info/?p=883&#34;&gt;http://blog.xiaoheshang.info/?p=883&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>