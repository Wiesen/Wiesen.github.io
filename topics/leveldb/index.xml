<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Leveldb on Wiesen&#39;s Blog</title>
    <link>http://wiesen.github.io/topics/leveldb/index.xml</link>
    <description>Recent content in Leveldb on Wiesen&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <atom:link href="http://wiesen.github.io/topics/leveldb/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Leveldb: Log</title>
      <link>http://wiesen.github.io/post/Leveldb-Storage-Log/</link>
      <pubDate>Sat, 28 Jan 2017 21:31:20 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/Leveldb-Storage-Log/</guid>
      <description>

&lt;p&gt;Log：(&lt;code&gt;db/log_format.h&lt;/code&gt;,&lt;code&gt;db/log_writer.h&amp;amp;.cc&lt;/code&gt;,&lt;code&gt;db/log_reader.h&amp;amp;.cc&lt;/code&gt;)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Introduction&lt;/p&gt;

&lt;p&gt;why log：log 文件在 LevelDb 中的主要作用是系统故障恢复时进行数据恢复。利用 WAL，即使系统发生故障，Memtable 中的数据没有来得及 Dump 到磁盘的 SSTable 文件，LevelDB 也可以根据 log 文件恢复 Memtable 中的数据。&lt;/p&gt;

&lt;p&gt;block of log：log 文件中的数据也是以 block 为单位组织（32k）。写日志时，一致性考虑，并没有按 block 单位写，每次更新均对 log 文件进行 IO，根据 WriteOption::sync 决定是否做强制 sync，读取时以 block 为单位做 IO 以及校验。&lt;/p&gt;

&lt;p&gt;log 的写入是顺序写，读取只会在启动时发生，不会是性能的瓶颈（每次写都 sync 会有影响），log 中的数据也就没有进行压缩处理。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Format&lt;/p&gt;

&lt;p&gt;block of log 的整体结构，以及 record 的组成：&lt;/p&gt;

&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;record0&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;record1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;record2&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;...&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;checksum (uint32)&lt;/td&gt;&lt;td&gt;length (uint16)&lt;/td&gt;&lt;td&gt;type (uint8)&lt;/td&gt;&lt;td&gt;data (length)&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
   

&lt;ol&gt;
&lt;li&gt;record： 每次更新写入作为一个 record

&lt;ul&gt;
&lt;li&gt;checksum 记录的是 type 和 data 的 crc 校验;   每个record都带上了32bit的checksum。对于每条记录多4字节还是很大开销的，这反映了leveldb的定位：针对fault-tolerant的分布式系统设计。&lt;/li&gt;
&lt;li&gt;length 是 record 内保存的 data 长度（little-endian）。&lt;/li&gt;
&lt;li&gt;为了避免 block 内部碎片的产生， 一份 record 可能会跨 block，所以根据 record 内保存数据占更新写入数据的完整与否， 当前分为 4 种 type： FULL， FIRST， MIDDLE， LAST, LAST，依次表示 record 内保存的是完整数据的全部，开始，中间或者最后部分。&lt;/li&gt;
&lt;li&gt;data 即是保存的数据。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;trailer： 如果 block 最后剩余的部分小于 record 的头长度(checksum/length/type 共 7bytes),则剩余的部分作为 block 的 trailer，填 0 不使用，record 写入下一个 block。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;log 文件格式：&lt;/p&gt;

&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;init_data&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;block1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;block2&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;blockN&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
&lt;li&gt;init_data: log 文件开头可以添加一些信息，读取写入的时候，跳过这些数据。&lt;/li&gt;
&lt;li&gt;block:实际的数据，binlog 以及 MANIFEST 文件都使用了这种 log 的格式。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Analysis&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;写入 （&lt;code&gt;Writer::AddRecord() log_writer.cc&lt;/code&gt;）&lt;/p&gt;

&lt;p&gt;对 log 的每次写入作为 record 添加：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果当前 block 剩余的 size 小于 record 头长度，填充 trailer，开始下一个 block。&lt;/li&gt;
&lt;li&gt;根据当前 block 剩余的 size 和写入 size，划分出满足写入的最大 record，确定 record type。&lt;/li&gt;
&lt;li&gt;写入 record（Writer::EmitPhysicalRecord()）&lt;/li&gt;
&lt;li&gt;循环 a-c,直至写入处理完成。&lt;/li&gt;
&lt;li&gt;根据 option 指定的 sync 决定是否做 log 文件的强制 sync。
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;读取（&lt;code&gt;Reader::ReadRecord() db/log_reader.cc&lt;/code&gt;）&lt;/p&gt;

&lt;p&gt;log 的读取仅发生在 db 启动的时候，每次读取出当时写入的一次完整更新：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;第一次读取， 根据指定的 &lt;code&gt;initial_offset&lt;/code&gt;_跳过 log 文件开始的 init_data(&lt;code&gt;Reader::SkipToInitialBlock()&lt;/code&gt;)，如果从跳过的 offset 开始，当前 block 剩余的 size 小于 record 的头长度（是个 trailer），则直接跳过这个 block。当前实现中指定的initial_offset_为 0。&lt;/li&gt;
&lt;li&gt;从 log 文件中读一个 record（&lt;code&gt;Reader::ReadPhysicalRecord()&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;根据读到 record 的 type 做进一步处理&lt;/li&gt;
&lt;li&gt;循环 a-c 直至读取出当时写入的一个完整更新。
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://luodw.cc/2015/10/18/leveldb-08/&#34;&gt;leveldb源码分析之读写log文件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mingxinglai.com/cn/2013/01/leveldb-log-and-env/&#34;&gt;LevelDB源码剖析之Env与log::Writer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;leveldb实现解析 by 淘宝-核心系统研发-存储 那岩&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Leveldb: Block Cache</title>
      <link>http://wiesen.github.io/post/Leveldb-Cache/</link>
      <pubDate>Wed, 25 Jan 2017 21:31:20 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/Leveldb-Cache/</guid>
      <description>

&lt;p&gt;Block Cache (&lt;code&gt;util/cache.cc&lt;/code&gt;)：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Introduction&lt;/p&gt;

&lt;p&gt;Cache 的目的：减少磁盘IO，加快 CURD 速度。&lt;/p&gt;

&lt;p&gt;leveldb 中的 cache 分为 Table Cache 和 Block Cache 两种，其中 Table Cache 中缓存的是 sstable 的索引数据，Block Cache 缓存的是 Block 数据（可选打开）。&lt;/p&gt;

&lt;p&gt;leveldb 中支持用户自己实现 block cache 逻辑，作为 option 传入。默认使用的是内部实现的 LRU。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;基于简单以及效率考虑，leveldb 中实现了一个简单的 hash table（LRUHandle），采用定长数组存放 node，链表解决 hash 冲突。每次 insert 后，如果 node 数量大于数组的容量（期望短的冲突链表长度），就将容量扩大2倍，做一次 rehash；&lt;/li&gt;
&lt;li&gt;LRU 的逻辑由 LRUCache 控制， insert 和 lookup 时更新链表即可；&lt;/li&gt;
&lt;li&gt;由于 levelDB 为多线程，每个线程访问 cache 时都会对 cache 加锁。为了保证多线程安全并且减少锁开销，又将 LRUCache 再做 shard（ShardedLRUCache）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;整体来看：ShardedLRUCache 内部有 16 个 LRUCache（定长），查找 Key 时根据 key 的高四位进行 hash 索引，然后在相应的 LRUCache 中进行查找或更新。当 LRUCache 使用率大于总容量后, 根据 LRU 淘汰 key.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/leveldb-cache.jpg&#34; alt=&#34;cache&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Declaration&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// A single shard of sharded cache.
class LRUCache {
 public:
  LRUCache();
  ~LRUCache();

  // Separate from constructor so caller can easily make an array of LRUCache
  void SetCapacity(size_t capacity) { capacity_ = capacity; }

  // Like Cache methods, but with an extra &amp;quot;hash&amp;quot; parameter.
  Cache::Handle* Insert(const Slice&amp;amp; key, uint32_t hash,
                        void* value, size_t charge,
                        void (*deleter)(const Slice&amp;amp; key, void* value));
  Cache::Handle* Lookup(const Slice&amp;amp; key, uint32_t hash);
  void Release(Cache::Handle* handle);
  void Erase(const Slice&amp;amp; key, uint32_t hash);

 private:
  void LRU_Remove(LRUHandle* e);
  void LRU_Append(LRUHandle* e);
  void Unref(LRUHandle* e);

  // Initialized before use.
  size_t capacity_;

  // mutex_ protects the following state.
  port::Mutex mutex_;
  size_t usage_;
  uint64_t last_id_;

  // Dummy head of LRU list.
  // lru.prev is newest entry, lru.next is oldest entry.
  LRUHandle lru_;
  HandleTable table_;
};

struct LRUHandle {
  void* value;//存储键值对的值
  void (*deleter)(const Slice&amp;amp;, void* value);//这个结构体的清除函数，由外界传进去注册
  LRUHandle* next_hash;//用于hash表冲突时使用
  LRUHandle* next;//当前节点的下一个节点
  LRUHandle* prev;//当前节点的上一个节点
  size_t charge;      // 这个节点占用的内存
  size_t key_length;//这个节点键值的长度
  uint32_t refs;//这个节点引用次数，当引用次数为0时，即可删除
  uint32_t hash;      // 这个键值的哈希值
  char key_data[1];   // 存储键的字符串，也是C++柔性数组的概念。
  Slice key() const {
    // For cheaper lookups, we allow a temporary Handle object
    // to store a pointer to a key in &amp;quot;value&amp;quot;.
    if (next == this) {
      return *(reinterpret_cast&amp;lt;Slice*&amp;gt;(value));
    } else {
      return Slice(key_data, key_length);
    }
  }//为了加速查询，有时候一个节点在value存储键。
};

class HandleTable {
 public:
  HandleTable() : length_(0), elems_(0), list_(NULL) { Resize(); }
  ~HandleTable() { delete[] list_; }

  LRUHandle* Lookup(const Slice&amp;amp; key, uint32_t hash) {}
  LRUHandle* Insert(LRUHandle* h) {}
  LRUHandle* Remove(const Slice&amp;amp; key, uint32_t hash) {}

 private:
  // The table consists of an array of buckets where each bucket is
  // a linked list of cache entries that hash into the bucket.
  uint32_t length_;//哈希数组的长度
  uint32_t elems_;//哈希表存储元素的数量
  LRUHandle** list_;//哈希数组指针，因为数组存储的是指针，所以类型必须是指针的指针


  // Return a pointer to slot that points to a cache entry that
  // matches key/hash.  If there is no such cache entry, return a
  // pointer to the trailing slot in the corresponding linked list.
  LRUHandle** FindPointer(const Slice&amp;amp; key, uint32_t hash) {}
  void Resize() {}
};  
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Analysis&lt;/p&gt;

&lt;p&gt;Cache类：一个抽象类，规范外部接口，用户可定义自己的 block cache，默认是调用 &lt;code&gt;NewLRUCache&lt;/code&gt; 返回一个 SharedLRUCache 对象。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Cache* NewLRUCache(size_t capacity) {
  return new SharedLRUCache(capacity);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SharedLRUCache类：内部有16个（&lt;code&gt;kNumShards&lt;/code&gt;） LRUCache 缓冲区，该类主要作用仅是计算 hash 值，选择 LRUCache ，然后调用 LRUCache 的函数。&lt;/p&gt;

&lt;p&gt;LRUCache 类：真正的缓冲区数据结构，每个缓冲区都维护了一个 LRU 双向链表和 hash 表。链表的元素类型为 LRUHandle；hash 表中的元素是 &lt;code&gt;LRUHandle *&lt;/code&gt;，用于快速判断数据是否在缓冲区中。&lt;/p&gt;

&lt;p&gt;LRUHandle 类：cache 中负责存储 key/value 的数据结构，是LRU 双向链表中的元素类型。&lt;code&gt;char key_data[1];&lt;/code&gt;为存储 key 的字符串，也是C++柔性数组的概念。&lt;code&gt;void* value;&lt;/code&gt;为存储 value&lt;/p&gt;

&lt;p&gt;HandleTable 类：为了保证哈希链的查找速度，尽量使平均哈希链长度为&amp;lt;=1。当元素的个数大于桶的数量时就重新 hash（resize 为当前 hash 表长度的2倍并 rehash），保证 hash 的时间复杂度为 O(1)。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://mingxinglai.com/cn/2013/01/leveldb-cache/&#34;&gt;LevelDB源码剖析之Cache缓冲区与hash表&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://luodw.cc/2015/10/24/leveldb-11/&#34;&gt;leveldb源码分析之Cache&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dirtysalt.github.io/leveldb.html#orgheadline188&#34;&gt;leveldb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Leveldb: Arena</title>
      <link>http://wiesen.github.io/post/Leveldb-Arena/</link>
      <pubDate>Fri, 20 Jan 2017 21:31:20 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/Leveldb-Arena/</guid>
      <description>&lt;p&gt;Arena：memtable 内存管理&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Introduction&lt;/p&gt;

&lt;p&gt;Leveldb 中使用 Arena 对 memtable 进行简单的内存管理，主要出于以下三个目的：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;封装内存操作以便进行内存使用统计：memtable 有阈值限制（write buffer size），通过统一的接口来分配不同大小的内存；&lt;/li&gt;
&lt;li&gt;保证内存对齐：Arena 每次按 klockSize(&lt;code&gt;static const int kBlockSize = 4096;&lt;/code&gt;)单位向系统申请内存，提供地址对齐内存，方便记录内存的使用并且提高内存使用效率；&lt;/li&gt;
&lt;li&gt;解决频繁分配小块内存降低效率，直接分配大块内存浪费内存的问题，同时避免个别大内存使用影响：当memtable申请内存时，若 &lt;code&gt;size &amp;lt;= kBlockSize / 4&lt;/code&gt; 则在当前的内存block中分配，否则直接向系统申请（new）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Arena 类内存管理方法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;采用 vector 来存储每次分配的内存，每一次分配的内存为一个块（block），block默认大小为4096kb；&lt;/li&gt;
&lt;li&gt;当达到阈值时将 dump to disk，完成后由析构函数完成所有内存的一次性释放，由于业务的特殊性因此无需提供内存释放的接口&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/arena.png&#34; alt=&#34;arena&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Declaration&lt;/p&gt;

&lt;p&gt;class Arena {
     public:
      Arena();
      ~Arena();&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  // Return a pointer to a newly allocated memory block of &amp;quot;bytes&amp;quot; bytes.
  char* Allocate(size_t bytes);

  // Allocate memory with the normal alignment guarantees provided by malloc
  char* AllocateAligned(size_t bytes);

  // Returns an estimate of the total memory usage of data allocated
  // by the arena (including space allocated but not yet used for user
  // allocations).
  size_t MemoryUsage() const {
    return blocks_memory_ + blocks_.capacity() * sizeof(char*);
  }

 private:
  char* AllocateFallback(size_t bytes);
  char* AllocateNewBlock(size_t block_bytes);

  // Allocation state
  char* alloc_ptr_;
  size_t alloc_bytes_remaining_;

  // Array of new[] allocated memory blocks
  std::vector&amp;lt;char*&amp;gt; blocks_;

  // Bytes of memory in blocks allocated so far
  size_t blocks_memory_;

  // No copying allowed
  Arena(const Arena&amp;amp;);
  void operator=(const Arena&amp;amp;);
};
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Analysis&lt;/p&gt;

&lt;p&gt;成员变量：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;char* alloc_ptr_;&lt;/code&gt;              // 内存的偏移量指针，即指向未使用内存的首地址&lt;/li&gt;
&lt;li&gt;&lt;code&gt;size_t alloc_bytes_remaining_;&lt;/code&gt; // 还剩下的内存数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;std::vector&amp;lt;char*&amp;gt; blocks_;&lt;/code&gt;    // 关键：存储每一次分配的内存指针&lt;/li&gt;
&lt;li&gt;&lt;code&gt;size_t blocks_memory_;&lt;/code&gt;         // 到目前为止分配的总内存
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;共有函数（接口）&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;inline char* Arena::Allocate(size_t bytes)&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;inline char* Arena::Allocate(size_t bytes) {
  // The semantics of what to return are a bit messy if we allow
  // 0-byte allocations, so we disallow them here (we don&#39;t need
  // them for our internal use).
  assert(bytes &amp;gt; 0);
  if (bytes &amp;lt;= alloc_bytes_remaining_) {
    char* result = alloc_ptr_;
    alloc_ptr_ += bytes;
    alloc_bytes_remaining_ -= bytes;
    return result;
  }
  return AllocateFallback(bytes);
}

char* Arena::AllocateFallback(size_t bytes) {
  if (bytes &amp;gt; kBlockSize / 4) {
    // Object is more than a quarter of our block size.  Allocate it separately
    // to avoid wasting too much space in leftover bytes.
    char* result = AllocateNewBlock(bytes);
    return result;
  }

  // We waste the remaining space in the current block.
  alloc_ptr_ = AllocateNewBlock(kBlockSize);
  alloc_bytes_remaining_ = kBlockSize;

  char* result = alloc_ptr_;
  alloc_ptr_ += bytes;
  alloc_bytes_remaining_ -= bytes;
  return result;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;该函数返回bytes字节的内存&lt;/li&gt;
&lt;li&gt;如果预先分配的内存(alloc_bytes&lt;em&gt;remaining&lt;/em&gt;)大于bytes,也就是说，预先分配的内存能够满足现在的需求，那就返回预先分配的内存，而不用向系统申请&lt;/li&gt;
&lt;li&gt;如果(alloc_bytes&lt;em&gt;remaining&lt;/em&gt; &amp;lt; bytes)，也就是说，预先分配的内存不能不够用，那就调用AllocateFallback来分配内存（分&lt;code&gt;size &amp;lt;= kBlockSize / 4&lt;/code&gt;进行区别处理）
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;char* Arena::AllocateAligned(size_t bytes)&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;char* Arena::AllocateAligned(size_t bytes) {
  const int align = sizeof(void*);    // We&#39;ll align to pointer size
  assert((align &amp;amp; (align-1)) == 0);   // Pointer size should be a power of 2
  size_t current_mod = reinterpret_cast&amp;lt;uintptr_t&amp;gt;(alloc_ptr_) &amp;amp; (align-1);
  size_t slop = (current_mod == 0 ? 0 : align - current_mod);
  size_t needed = bytes + slop;
  char* result;
  if (needed &amp;lt;= alloc_bytes_remaining_) {
    result = alloc_ptr_ + slop;
    alloc_ptr_ += needed;
    alloc_bytes_remaining_ -= needed;
  } else {
    // AllocateFallback always returned aligned memory
    result = AllocateFallback(bytes);
  }
  assert((reinterpret_cast&amp;lt;uintptr_t&amp;gt;(result) &amp;amp; (align-1)) == 0);
  return result;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;首先获取一个指针的大小&lt;code&gt;const int align = sizeof(void*)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;然后将我们使用的char * 指针地址转换为一个无符号整型(reinterpret_cast&lt;uintptr_t&gt;(result):It is an unsigned int that is guaranteed to be the same size as a pointer.)&lt;/li&gt;
&lt;li&gt;通过与操作来获取&lt;code&gt;size_t current_mod = reinterpret_cast&amp;lt;uintptr_t&amp;gt;(alloc_ptr_) &amp;amp; (align-1)&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;当前指针模4的值，有了这个值以后，我们就容易知道，还差 &lt;code&gt;slop = align - current_mod&lt;/code&gt; 个字节内存才能对齐，即&lt;code&gt;result = alloc_ptr + slop&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;size_t MemoryUsage() const&lt;/code&gt;：仅仅是计算内存使用情况，不赘述&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ctor &amp;amp; dtor：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Arena::Arena() {
  blocks_memory_ = 0;
  alloc_ptr_ = NULL;  // First allocation will allocate a block
  alloc_bytes_remaining_ = 0;
}

Arena::~Arena() {
  for (size_t i = 0; i &amp;lt; blocks_.size(); i++) {
    delete[] blocks_[i];
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Arena::Arena()&lt;/code&gt;：初始化各个成员变量&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Arena::~Arena()&lt;/code&gt;：释放各个 vector block 的内存
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Leveldb: Storage MemTable</title>
      <link>http://wiesen.github.io/post/leveldb-Storage-MemTable/</link>
      <pubDate>Tue, 20 Dec 2016 21:31:20 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/leveldb-Storage-MemTable/</guid>
      <description>

&lt;p&gt;Leveldb 存储主要分为 SSTable（磁盘） 和 MemTable（内存，包括 MemTable 和 Immutable MemTable），此外还有一些辅助文件:Manifest, Log, Current。&lt;/p&gt;

&lt;h2 id=&#34;memtable-db-skiplist-h-db-memtable-h-memtable-cc&#34;&gt;Memtable (&lt;code&gt;db/skiplist.h&lt;/code&gt;,&lt;code&gt;db/memtable.h &amp;amp; memtable.cc&lt;/code&gt;)&lt;/h2&gt;

&lt;div style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/leveldb-architecture.png&#34; width=&#34;500&#34;/&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Introduction&lt;/p&gt;

&lt;p&gt;MemTable 是 leveldb 的 kv 数据在内存中的存储结构。当 Memtable 写入的数据占用内存到达指定大小 (Options.write_buffer_size)，则自动转换为 Immutable Memtable（只读），同时生成新的 Memtable 供写操作写入新数据。后台的 compact 进程会负责将 immutable memtable dump to disk 生成 sstable。&lt;/p&gt;

&lt;p&gt;MemTable 提供内存中 KV entry 的 Add 和 Get 操作接口。 Memtable 实际上并不存在 Delete 操作，删除某个 Key 的 Value 在 Memtable 内是作为插入一条记录实施的，但是会打上一个 Key 的删除标记，真正的删除操作是 Lazy 的，会在以后的 Compaction 过程中删除这个 KV。&lt;/p&gt;

&lt;p&gt;Memtable 类只是一个接口类，其底层实现依赖于两大核心组件 Arena 和 SkipList。其中 Arena 内存分配器统一管理内存，SkipList 用于实际 KV 存储。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Component&lt;/p&gt;

&lt;p&gt;Arena： memtable 内存管理&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;封装内存操作以便进行内存使用统计：memtable 有阈值限制（write buffer size），通过统一的接口来分配不同大小的内存；&lt;/li&gt;
&lt;li&gt;预先分配一整块内存来&lt;/li&gt;
&lt;li&gt;保证内存对齐：Arena 每次按 klockSize(&lt;code&gt;static const int kBlockSize = 4096;&lt;/code&gt;)单位向系统申请内存，提供地址对齐内存，方便记录内存的使用并且提高内存使用效率；&lt;/li&gt;
&lt;li&gt;解决频繁分配小块内存降低效率，直接分配大块内存浪费内存的问题，同时避免个别大内存使用影响：当memtable申请内存时，若 &lt;code&gt;size &amp;lt;= kBlockSize / 4&lt;/code&gt; 则在当前的内存block中分配，否则直接向系统申请（new）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;SkipList：memtable 的实际数据结构&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;根据上一篇 blog 中 LSM tree 的性质，table 应当保持有序性。而对一个排序结构执行插入操作开销很大（随机写），通常性能瓶颈集中在这里。一些数据结构如链表, AVL 树, B 树, skiplist 等都加速了随机写。leveldb 的 memtable 实现没有使用复杂的 B 树，采用更轻量级的 &lt;a href=&#34;https://en.wikipedia.org/wiki/Skip_list&#34;&gt;skiplist&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;skiplist 是一种可以代替平衡树的数据结构。其从概率上保证数据平衡（依赖于系统设计时的随机假设），结构和实现比平衡树简单。概率上时间复杂度近似 O(logN)，与平衡树相同，但空间上比较节省，一个节点平均只需要 1.333 个指针。&lt;/li&gt;
&lt;li&gt;Leveldb 中，Skiplist 中的操作不需要任何锁或者 node 的引用计数，利用内存屏障来进行线程同步，原因主要为以下两个：

&lt;ol&gt;
&lt;li&gt;Skiplist 中 node 内保存的是 InternalKey 与对应 value 组成的数据，SequenceNumber 的全局唯一保证了不会有相同的弄得出现，因此保证了不会有node更新的情况；&lt;/li&gt;
&lt;li&gt;delete 操作等同于 put 操作，因此不会需要引用计数记录 node 的生存周期。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Declaration&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class MemTable {
 public:
  // MemTables are reference counted.  The initial reference count
  // is zero and the caller must call Ref() at least once.
  explicit MemTable(const InternalKeyComparator&amp;amp; comparator);

  // Increase reference count.
  void Ref() { ++refs_; }

  // Drop reference count.  Delete if no more references exist.
  void Unref() {
    --refs_;
    assert(refs_ &amp;gt;= 0);
    if (refs_ &amp;lt;= 0) {
      delete this;
    }
  }

  // Returns an estimate of the number of bytes of data in use by this data structure.
  // REQUIRES: external synchronization to prevent simultaneous operations on the same MemTable.
  size_t ApproximateMemoryUsage();

  // Return an iterator that yields the contents of the memtable.
  //
  // The caller must ensure that the underlying MemTable remains live
  // while the returned iterator is live.  The keys returned by this
  // iterator are internal keys encoded by AppendInternalKey in the
  // db/format.{h,cc} module.
  Iterator* NewIterator();

  // Add an entry into memtable that maps key to value at the
  // specified sequence number and with the specified type.
  // Typically value will be empty if type==kTypeDeletion.
  void Add(SequenceNumber seq, ValueType type,
           const Slice&amp;amp; key,
           const Slice&amp;amp; value);

  // If memtable contains a value for key, store it in *value and return true.
  // If memtable contains a deletion for key, store a NotFound() error in *status and return true.
  // Else, return false.
  bool Get(const LookupKey&amp;amp; key, std::string* value, Status* s);

 private:
  ~MemTable();  // Private since only Unref() should be used to delete it

  struct KeyComparator {
    const InternalKeyComparator comparator;
    explicit KeyComparator(const InternalKeyComparator&amp;amp; c) : comparator(c) { }
    int operator()(const char* a, const char* b) const;
  };
  friend class MemTableIterator;
  friend class MemTableBackwardIterator;

  typedef SkipList&amp;lt;const char*, KeyComparator&amp;gt; Table;

  KeyComparator comparator_;
  int refs_;
  Arena arena_;
  Table table_;

  // No copying allowed
  MemTable(const MemTable&amp;amp;);
  void operator=(const MemTable&amp;amp;);
};
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Coding &amp;amp; Function Analysis&lt;/p&gt;

&lt;p&gt;构造和析构：MemTable 的对象构造必须显式调用，重点在于初始 Arena 和 SkipList 两大核心组件，且提供引用计数初始为 0，使用时必须先 Ref()，实际对象销毁在 Unref() 引用计数为 0 时。&lt;/p&gt;

&lt;p&gt;C++ class基本功（正确管理内存和其他资源）：MemTable class 由 &lt;code&gt;Unref()&lt;/code&gt; 完成实际的内存释放操作，因此 Leveldb 中禁用了 copy ctor 和 assignment operator（声明为private，并且只提供声明，而不提供定义）（C++11 中可以使用 = delete)&lt;/p&gt;

&lt;p&gt;功能：memtable 对 key 的查找和遍历是 MemTableIterator，而 MemTableIterator 实际上是 SkipList iterator wrapper。NewIterator 即是返回一个 MemTableIterator，用于有序遍历 memtable 的存储数据。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;写入： &lt;code&gt;void Add(SequenceNumber seq, ValueType type, const Slice&amp;amp; key, const Slice&amp;amp; value)&lt;/code&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Encode：将传入的参数封装为 &lt;code&gt;Internalkey&lt;/code&gt;，然后与 &lt;code&gt;value&lt;/code&gt; 一起编码成前述（Leveldb setting） entry&lt;/li&gt;
&lt;li&gt;Insert 到实际数据结构：&lt;code&gt;SkipList::Insert()&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;读取： &lt;code&gt;bool Get(const LookupKey&amp;amp; key, std::string* value, Status* s)&lt;/code&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;从传入的 &lt;code&gt;LookupKey&lt;/code&gt; 中获取 &lt;code&gt;memtable_key&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MemTableIterator::Seek()&lt;/code&gt; 返回 &lt;code&gt;MemTableIterator&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;对 &lt;code&gt;MemTableIterator&lt;/code&gt; 的 key 进行还原，并对 key 后面的8个字节解码，以此判断消息是什么类型&lt;/li&gt;
&lt;li&gt;a) &lt;code&gt;kTypeValue&lt;/code&gt; 表有效数据，返回对应的 &lt;code&gt;value&lt;/code&gt; 数据; b) &lt;code&gt;kTypeDeletion&lt;/code&gt; 表无效数据，设置 Status 为 NotFound&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;没有删除：前面说过，memtable 的 delete 是 lazy 的，实际上是 add 一条 &lt;code&gt;ValueType&lt;/code&gt; 为 &lt;code&gt;kTypeDeletion&lt;/code&gt; 的记录。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/sparkliang/article/details/8567602&#34;&gt;Leveldb 源码分析 &amp;ndash;1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mingxinglai.com/cn/2013/01/leveldb-memtable/&#34;&gt;LevelDB : MemTable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://luodw.cc/2015/10/16/leveldb-05/&#34;&gt;leveldb skiplist 实现分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pandademo.com/2016/03/memtable-and-skiplist-leveldb-source-dissect-3/&#34;&gt;MemTable 与 SkipList-leveldb 源码剖析 (3)&lt;/a&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Leveldb: Basic Settings</title>
      <link>http://wiesen.github.io/post/Leveldb-Basic-Concept/</link>
      <pubDate>Mon, 19 Dec 2016 21:31:20 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/Leveldb-Basic-Concept/</guid>
      <description>

&lt;p&gt;（待完善……）&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Slice(&lt;code&gt;include/leveldb/slice.h&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;为操作数据的方便，将数据和长度包装成 Slice 使用，直接操控指针以避免不必要的数据拷贝&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Slice {
    … 
    private: 
        const char* data_; 
        size_t size_; 
};
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Optin(&lt;code&gt;include/leveldb/option.h&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;leveldb 中启动时的一些配置，通过 Option 传入，get/put/delete 时，也有相应的 ReadOption/WriteOption。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Env(&lt;code&gt;include/leveldb/env.h&lt;/code&gt; &lt;code&gt;util/evn_posix.h&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;考虑到移植以及灵活性，leveldb 将系统相关的处理（文件/进程/时间之类）抽象成 Env，用户可以自己实现相应的接口，作为 Option 传入。默认使用自带的实现。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;varint(&lt;code&gt;util/coding.h&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;leveldb 采用了 protocalbuffer 里使用的变长整形编码方法，节省空间。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ValueType(&lt;code&gt;db/dbformat.h&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;leveldb更新（put/delete）某个key时不会操控到db中的数据，每次操作都是直接新插入一份kv数据，具体的数据合并和清除由后台的compact完成。&lt;/p&gt;

&lt;p&gt;所以，每次 put 都会添加一份 KV 数据，即使该 key 已经存在；而 delete 等同于 put 空的 value。为了区分 live 数据和已删除的 mock 数据，leveldb 使用 ValueType 来标识：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;enum ValueType { 
    kTypeDeletion = 0x0, 
    kTypeValue = 0x1 
};
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;SequenceNumber(&lt;code&gt;db/dbformat.h&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;leveldb中的每次更新（put/delete) 操作都拥有一个版本，由 SequnceNumber 来标识，整个db有一个全局值保存着当前使用到的SequnceNumber。SequnceNumber 在 leveldb 有重要的地位，key 的排序，compact 以及 snapshot 都依赖于它。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;typedef uint64_t SequenceNumber&lt;/code&gt;: 存储时，SequnceNumber 只占用56 bits, ValueType 占用8 bits，二者共同占用 64bits（uint64_t).&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;0-56&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;56-64&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SequnceNumber&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;ValueType&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;user_key &amp;amp; memtable_key &amp;amp; internal_key&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;user_key: 用户使用的 key&lt;/li&gt;
&lt;li&gt;memtable_key: memtable 中使用的 key&lt;/li&gt;
&lt;li&gt;internal_key: sstable 中使用的 key&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;InternalKey(&lt;code&gt;db/dbformat.h&lt;/code&gt;) &amp;amp; ParsedInternalKey (&lt;code&gt;db/dbformat.h&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;InternalKey: userkey ＋ 元信息（8 bytes, SequnceNumber|ValueType), ParsedInternalKey 为 InternalKey 分拆得到的结构体&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class InternalKey {
    …
    private:
        std::string rep_;
}

struct ParsedInternalKey { 
    Slice user_key; 
    SequenceNumber sequence; 
    ValueType type; 
};
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;LookupKey(&lt;code&gt;db/dbformat.h&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;db 内部为查找 memtable/sstable 方便而设置的类：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class LookupKey { 
    … 
    private: 
        const char* start_;
        const char* kstart_;
        const char* end_;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;start_&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;kstart_ - end_&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;internal_key_size&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;internal_key: userkey_data + SequenceNumber&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;(varint32)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;(InternalKey_size: char[] + uint64)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;对 memtable lookup 时使用 &lt;code&gt;memtable_key&lt;/code&gt; [&lt;code&gt;start_&lt;/code&gt;,&lt;code&gt;end_&lt;/code&gt;], 对 sstable lookup 时使用 &lt;code&gt;internal_key&lt;/code&gt; [&lt;code&gt;kstart_&lt;/code&gt;, &lt;code&gt;end_&lt;/code&gt;]。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/leveldb_key.png&#34; width=&#34;450&#34;/&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;memtable entry&lt;/p&gt;

&lt;p&gt;MemTable 中 entry 存储格式（实际上是字符串）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/leveldb_memtable_entry.png&#34; width=&#34;600&#34;/&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Comparator(&lt;code&gt;include/leveldb/comparator.h&lt;/code&gt; &lt;code&gt;util/comparator.cc&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;InternalKeyComparator(&lt;code&gt;db/dbformat.h&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;WriteBatch(&lt;code&gt;db/write_batch.cc&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;FileMetaData(&lt;code&gt;db/version_edit.h&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;block(&lt;code&gt;table/block.cc&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;BlockHandle(&lt;code&gt;table/dbformat.h&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;FileNumber(&lt;code&gt;db/dbformat.h&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;filename(&lt;code&gt;db/dbformat.cc&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Compact(&lt;code&gt;db/db_impl.cc&lt;/code&gt; &lt;code&gt;db/version_set.cc&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Iterator(&lt;code&gt;include/leveldb/iterator.h&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;leveldb实现解析 by 淘宝-核心系统研发-存储 那岩&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pandademo.com/2016/03/memtable-and-skiplist-leveldb-source-dissect-3/&#34;&gt;MemTable 与 SkipList-leveldb 源码剖析 (3)&lt;/a&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Leveldb: Introduction</title>
      <link>http://wiesen.github.io/post/leveldb-Introduction/</link>
      <pubDate>Mon, 28 Nov 2016 21:31:20 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/leveldb-Introduction/</guid>
      <description>

&lt;p&gt;看了不少 blog 分析 leveldb，但很少看到有人从设计原因和策略上进行总结。所以这个系列对 leveldb 的实现做一点设计分析，争取将内部实现逻辑串联起来，至于源码注释之类的网上一扒拉就有很多啦。&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Leveldb 库提供持久层 kv 存储，其中 keys 和values 可以是任意字节数组。目前有 C++，golang 的实现。&lt;/p&gt;

&lt;p&gt;作者 Jeff Dean, Sanjay Ghemawat 同时也是设计实现 BigTable 的作者。在 BigTable 中有两个关键部分：master server 和 tablet server。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;master server 负责存储 meta-data，并且调度管理 tablet server；&lt;/li&gt;
&lt;li&gt;tablet server 负责存储具体数据，并且响应读写操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Leveldb 可视为 BigTable 中 tablet server 的简化实现。&lt;/p&gt;

&lt;h2 id=&#34;features-limitations-performance&#34;&gt;Features, Limitations, Performance&lt;/h2&gt;

&lt;p&gt;详见 &lt;a href=&#34;https://github.com/google/leveldb&#34;&gt;leveldb homepage&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;how-to-use&#34;&gt;How to use&lt;/h2&gt;

&lt;p&gt;详见 &lt;a href=&#34;https://github.com/google/leveldb/blob/master/doc/index.html&#34;&gt;leveldb 使用文档&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;冯诺依曼体系结构的计算机系统主要为两点：&lt;strong&gt;存储 + 计算&lt;/strong&gt;。数据库即为存储方面，依赖于存储硬件特性。&lt;/p&gt;

&lt;p&gt;当前磁盘物理结构特性导致 (磁头寻道，旋转延迟)：&lt;strong&gt;随机读写慢，连续读写快&lt;/strong&gt;，相差三个数量级。内存和 SSD 同样表现，只不过原因是：连续读写可预判，因此会被优化 (相差量级也没磁盘那么大)。&lt;/p&gt;

&lt;p&gt;上述说明：基于目前这样的硬件特性，我们设计存储系统时要&lt;strong&gt;尽量避免随机读写，设计为顺序读写&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;然而，顺序读和顺序写是相互矛盾的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;为了优化读效率，最好是将以有序方式组织数据从而写入相邻的块，以维护顺序读，而这增加了随机写；&lt;/li&gt;
&lt;li&gt;为了优化写效率，最好是所有的写都是增量写，也就是顺序写，而这增加了随机读。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;题外话：常见的优化读操作性能的设计有：二分、hash、B+ 树等。这些方法使用各种查找结构来组织数据，有效提升读操作性能(最少提供了O(logN))，但是增加了随机写操作，大大降低了写操作性能。&lt;/p&gt;

&lt;p&gt;因此，如果一个业务&lt;strong&gt;对写操作的吞吐量十分敏感，或者写操作数量远远大于读操作&lt;/strong&gt;，那么应该采取的措施是：&lt;strong&gt;优化写操作，也就是尽量将写操作设计为增量写&lt;/strong&gt;，从而尽可能地减少寻道，以达到磁盘理论写入速度最大值。&lt;/p&gt;

&lt;p&gt;这个策略常用于日志或者堆文件这种业务场景中，因为它们是完全顺序的（包括读写），所以可以提供很好的写操作性能。&lt;/p&gt;

&lt;h2 id=&#34;leveldb-core-idea&#34;&gt;Leveldb Core Idea&lt;/h2&gt;

&lt;p&gt;以 &lt;strong&gt;LSM(Log Structured Merge) Tree&lt;/strong&gt;组织数据从而将逻辑场景中的写请求转换为顺序写，辅以 &lt;strong&gt;Bloom Filter&lt;/strong&gt; 和 &lt;strong&gt;Shard LRU cache&lt;/strong&gt; 等策略优化随机读操作从而保证读效率。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Log-structured_merge-tree&#34;&gt;&lt;strong&gt;LSM tree&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;关于论文的部分分析详见&lt;a href=&#34;https://blog.acolyer.org/2014/11/26/the-log-structured-merge-tree-lsm-tree/&#34;&gt;链接&lt;/a&gt;&lt;/p&gt;

&lt;div style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/memtable.png&#34; width=&#34;500&#34;/&gt; &lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/compaction.png&#34; width=&#34;500&#34;/&gt;
&lt;/div&gt;

&lt;p&gt;LSM tree 针对&lt;strong&gt;写入速度瓶颈问题&lt;/strong&gt;而提出的方法，其基本思想是：&lt;strong&gt;将随机写转换为顺序写，交换读和写的随机 IO&lt;/strong&gt;。主要组成结构为：MemTable（内存中）+ SSTable (Sorted String Table)&lt;/p&gt;

&lt;p&gt;首先数据更新增量写入 MemTable，其后保存为有序文件 SSTable 到磁盘中（read only），每个文件保存一段时间内的数据更新。为了均衡读写效率，SSTable 文件是一种分层次（level）管理。&lt;/p&gt;

&lt;p&gt;LSM Tree 的主要措施有:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对更新进行批量 &amp;amp; 延时处理 (超过大小阈值后将内存中的数据 dump 到磁盘中)：减少寻道，提高写操作性能；&lt;/li&gt;
&lt;li&gt;周期性地利用归并排序对磁盘文件执行合并操作 (compaction)：移除已删除和冗余数据，减少文件个数，保证读操作性能；&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Bloom_filter&#34;&gt;&lt;strong&gt;Bloom Filter&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;div style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/bloomfilter.png&#34; width=&#34;550&#34;/&gt;
&lt;/div&gt;
    

&lt;p&gt;由于 LSM Tree 会产生大量文件，因此 LevelDb 利用 bloomfilter 来避免大量的读操作。&lt;/p&gt;

&lt;p&gt;bloomfilter 以概率性算法高效检索一个 key 是否在一个 SSTable (核心为 hash，若判断为不存在则必定不存在，若判断为存在则可能不存在)。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_Recently_Used_.28LRU.29&#34;&gt;&lt;strong&gt;Shard LRU Cache&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;leveldb 中的 cache 分为 Table Cache 和 Block Cache 两种，其中 Table Cache 中缓存的是 sstable 的索引数据，Block Cache 缓存的是 Block 数据（可选打开）。&lt;/p&gt;

&lt;p&gt;由于 levelDB 为多线程，每个线程访问 cache 时都会对 cache 加锁。为了保证多线程安全并且减少锁开销，leveldb 定义了一个 SharedLRUCache。&lt;/p&gt;

&lt;p&gt;ShardedLRUCache 内部有 16 个 LRUCache，查找 Key 时根据 key 的高四位进行 hash 索引，然后在相应的 LRUCache 中进行查找或更新。当 LRUCache 使用率大于总容量后, 根据 LRU 淘汰 key.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;overall-architecture&#34;&gt;Overall Architecture&lt;/h2&gt;

&lt;div style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/leveldb-architecture.png&#34; width=&#34;500&#34;/&gt;
&lt;/div&gt;

&lt;p&gt;Leveldb 存储主要分为 SSTable 和 MemTable（即 LSM Tree），前者为不可变且存储于持久设备上，后者位于内存上并且可变。其中有两个 MemTable，一个为当前写入 MemTable，另一个为等待持久化的 Immutable MemTable。此外还有一些辅助文件，后面详述。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Write Operation&lt;/strong&gt;：当用户需要插入一条 kv 到 Leveldb 中时，首先会被存储到 log 中 &lt;strong&gt;(Write Ahead Log, WAL, 保证数据持久性)&lt;/strong&gt;；然后插入到 MemTable 中；当 MemTable 达到一定大小后会转化为 read-only Immutable MemTable，并且创建一个新的 MemTable；同时开启一个新的后台线程将 Immutable MemTable 的内容 dump 到磁盘中，创建一个新的 SSTable；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deletion Operation&lt;/strong&gt;：在 Leveldb 中视为特殊的 Write operation，写入一个 deletion marker。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Read Operation&lt;/strong&gt;：当 leveldb 收到一个 Get 请求时，首先会在 MemTable 进行查找；然后在 Immutable MemTable 查找；最后在 SSTable 中查找（从 level 0 到 higher level），直到匹配到一个 kv item 或者为 NULL。&lt;/p&gt;

&lt;h2 id=&#34;file-layout&#34;&gt;File Layout&lt;/h2&gt;

&lt;p&gt;详见 &lt;a href=&#34;https://github.com/google/leveldb/blob/master/doc/impl.html&#34;&gt;leveldb 实现文档&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;source-code-structure&#34;&gt;Source Code Structure&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;leveldb-1.4.0  
|
+--- port           &amp;lt;=== 提供各个平台的基本接口
|
+--- util           &amp;lt;=== 提供一些通用工具类
|
+--- helpers
|      |
|      +--- memenv  &amp;lt;=== Env 的一个具体实现(Env 是 leveldb 封装的运行环境)
|
+--- table          &amp;lt;=== sstable 相关的数据格式定义和操作实现
|
+--- db             &amp;lt;=== 主要逻辑的实现
|
+--- doc
|     |
|     +--- table_format.txt   &amp;lt;=== 磁盘文件数据结构说明
|     |
|     +--- log_format.txt     &amp;lt;=== 日志文件（用于宕机恢复未刷盘的数据）数据结构说明
|     |
|     +--- impl.html          &amp;lt;=== 一些实现
|     |
|     +--- index.html         &amp;lt;=== 使用说明
|     |
|     +--- bench.html         &amp;lt;=== 测试数据
|
+--- include
     |
     +--- leveldb           &amp;lt;=== 所有头文件
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Reference：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://zouzls.github.io/2016/11/23/LevelDB%E4%B9%8BLSM-Tree/&#34;&gt;LevelDB 之 LSM-Tree&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://brg-liuwei.github.io/tech/2014/10/15/leveldb-0.html&#34;&gt;和我一起学习 leveldb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.open-open.com/lib/view/open1424916275249.html&#34;&gt;Log Structured Merge Trees(LSM) 原理&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>