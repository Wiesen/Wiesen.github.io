<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mit 6.824 on Wiesen&#39;s Blog</title>
    <link>http://wiesen.github.io/topics/mit-6.824/index.xml</link>
    <description>Recent content in Mit 6.824 on Wiesen&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <atom:link href="http://wiesen.github.io/topics/mit-6.824/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>MIT 6.824: Lab 4 Sharded KeyValue Service Implementation</title>
      <link>http://wiesen.github.io/post/MIT-6.824-Lab4-Sharded-KeyValue-Service/</link>
      <pubDate>Fri, 09 Sep 2016 17:32:46 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/MIT-6.824-Lab4-Sharded-KeyValue-Service/</guid>
      <description>

&lt;p&gt;lab4 是基于 lab2 和 lab3 实现的 Raft Consensus Algorithm 之上实现 Sharded KeyValue Service。主要分为两部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Part A：The Shard Master&lt;/li&gt;
&lt;li&gt;Part B: Sharded Key/Value Server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了最后一个 challenge test case &lt;code&gt;TestDelete()&lt;/code&gt; 以外，目前代码其余都可以 pass。但偶尔会 fail 在 unreliable test case，目前的定位是 raft 的实现还有点 bug。&lt;/p&gt;

&lt;p&gt;Code Link:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Wiesen/MIT-6.824/tree/master/2016/shardmaster&#34;&gt;PART A&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Wiesen/MIT-6.824/tree/master/2016/shardkv&#34;&gt;PART B&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;

&lt;p&gt;lab4 的架构是典型的 M/S 架构（a configuration service and a set of replica groups)，不过实现十分基础，很多功能没有实现：1) shards 之间的传递很慢并且不允许 concurrent client acess；2) 每个 raft group 中的 member 不会改变。&lt;/p&gt;

&lt;p&gt;configuration service&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;由若干 shardmaster 利用 raft 协议保证一致性的集群；&lt;/li&gt;
&lt;li&gt;管理 configurations 的顺序：每个 configuration 描述 replica group 以及每个 group 分别负责存储哪些 shards；&lt;/li&gt;
&lt;li&gt;响应 Join/Leave/Move/Query 请求，并且对 configuration 做出相应的改变；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;replica group&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;由若干 shardkv 利用 raft 协议保证一致性的集群；&lt;/li&gt;
&lt;li&gt;负责具体数据的存储（一部分），组合所有 group 的数据即为整个 database 的数据；&lt;/li&gt;
&lt;li&gt;响应对应 shards 的 Get/PutAppend 请求，并保证 linearized；&lt;/li&gt;
&lt;li&gt;周期性向 shardmaster 进行 query 获取 configuration，并且进行 migration 和 update；&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;part-a-the-shard-master&#34;&gt;Part A：The Shard Master&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;RPC Join/leave/Move/Query&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Client:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;at most once semantics：每个 Client 及 每个 Request 赋予唯一的 id；&lt;/li&gt;
&lt;li&gt;sequential consistency：对于每个 Client，仅有一条 Request RPC 在显式执行；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Server:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;异步：开一个 goroutine 来监听和处理 accept entry，与各 RPC 中的 start entry 分离，利用 channel 进行同步和通信；&lt;/li&gt;
&lt;li&gt;at most once semantics：主要针对写操作，本文在 accept operation 处进行 duplicated check (也可以在 start operation 处再加一层)，对于重复的 request，仅向 client 回复操作结果；&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Rebanlancing&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;lab4 对 shards 分配的要求是: divide the shards as evenly as possible among the groups, and should move as few shards as possible to achieve that goal.&lt;/p&gt;

&lt;p&gt;最直接的做法是: 首先计算每个 replica group 分配多少个 shards ( &lt;code&gt;quota = num_of_shards / num_of_group&lt;/code&gt;, &lt;code&gt;remain = num_of_shards - num_of_group * quota&lt;/code&gt;，然后依据 &lt;code&gt;num_of_server&lt;/code&gt; 对 replica group 进行排序，server 数量多的 group 分配 shards 个数 &lt;code&gt;quota + 1&lt;/code&gt;，其余分配 &lt;code&gt;quota&lt;/code&gt; )，最后把 shards 从多的 group 移动到少的 group。&lt;/p&gt;

&lt;p&gt;然而，在 go 中实现上面的做法并不是那么 clean，很多特性在语言层面上并不支持，比如: 1) get map.keys(); 2) 根据特定的字段进行排序等，自行实现实在麻烦。&lt;/p&gt;

&lt;p&gt;因此，由于 lab 中只有 join/leave 会造成 imbalance，并且 group 是逐个 join/leave。所以 simple first，首先统计 prior config 中每个 group 有多少个 shards，并且计算 present config 中平均每个 group 分配多少个 shards (&lt;code&gt;quota = num_of_shards / num_of_group&lt;/code&gt;)，然后循环将 max_shards_group/leaving_group 中的 shards 分配给 joining_group/min_shards_group.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;part-b-sharded-key-value-server&#34;&gt;Part B: Sharded Key/Value Server&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;RPC PutAppend/Get/TransferShard&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hint: Think about how the shardkv client and server should deal with ErrWrongGroup. Should the client change the sequence number if it receives ErrWrongGroup ? Should the server update the client state if it returns ErrWrongGroup when executing a Get / Put request?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;绝大部分与 Part A 一样，除了 ErrWrongGroup 的异常处理。&lt;/p&gt;

&lt;p&gt;当 server 发现 ErrWrongGroup 时，不需要 update client state；当 client 收到 ErrWrongGroup 时，不需要改变 operation sequence number，换个 group 继续 request 即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Migrating Shard&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hint: When groups move shards, they need to move some duplicate detection state as well as the key/value data. Think about how the receiver of a shard should update its own duplicate detection state. Is it correct for the receiver to entirely replace its state with the received one?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;假设&lt;/strong&gt;: configuration 由 cfg1 —&amp;gt; cfg2，shard S1 由 G1 -&amp;gt; G2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;How to migrate - push or pull&lt;/strong&gt;: 这时应该由 G1 push S1 还是由 G2 pull S1？一般来说，G2 完成 reconfig 操作后，随时会有针对 migrated shard 的 get/put/append 操作。如果由 G1 push S1，那么就无法保证 migrated shard 什么时候完成，出现错误。所以应该由 G2 在进行 reconfig 时进行 pull;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Response to migration&lt;/strong&gt;: 由于 lab 中 group 是逐个 join/leave，同一个 group 不会同时迁入和迁出 shards，亦即是迁入和迁出 shards 的 groups 不会相交。因此当 G1 处于 cfg2 时，G1 已经不再负责 S1，之后可随时响应 migration 迁出 S1。亦即是：当 G1.cfg.num &amp;gt; G2.cfg.num 才能响应 migration，否则必须等待 G1 更新完毕 (避免互相请求出现死锁)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reconfiguration&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hint: Process re-configurations one at a time, in order.&lt;/p&gt;

&lt;p&gt;Hint: When group G1 needs a shard from G2 during a configuration change, does it matter at what point during its processing of log entries G2 sends the shard to G1?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Detect&lt;/strong&gt;: 开一个 goroutine 来周期性地向 shardmaster query 最新的 configuration (由 group leader 完成)，当发现 configuration 更新时 (one by one in order)，即向其余 group 获取需要的 shards (migrating shard)；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;When to reconfigurate&lt;/strong&gt;: Reconfiguration operation 仅仅是 group leader 从 shardmaster 获取到的 operation proposal，新的 configuration 什么时候生效是由各 group 自身决定，本文的实现是当 group 获取到需要的 shards 后再进行 reconfiguration update。因此会出现当 client 根据新的 configuration 向 shardkv 发起 request 时，各个 group 都还没完成 configuration update。不过这并没什么影响，我们可以让 client 一直 loop 向每个 replica group 发起 request (当然是一直被拒)，直到目标 group 完成 reconfiguration update;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Reconfiguration operation 会影响到 PutAPpend/Get，因此同样需要利用 raft 保证 group 内的一致性，确保集群内完成了之前的操作后同时进行 Reconfiguration；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Replace What&lt;/strong&gt;: 包括 config，StoreShard (data) 以及 Ack (duplicate detection)，其中 Ack 不是 replace entirely，仅当 kv.ack[clientId] &amp;lt; migration.Ack[clientId] 才更新；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bluesea147/6.824/blob/master/src/shardmaster/server.go&#34;&gt;bluesea147/6.824/shardmaster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/bluesea147/6.824/blob/master/src/shardkv/server.go&#34;&gt;bluesea147/6.824/shardkv&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>MIT 6.824: lab3 Fault-Tolerant Key/Value Service Implementation</title>
      <link>http://wiesen.github.io/post/MIT-6.824-lab3-Fault-Tolerant-KVService-Implementation/</link>
      <pubDate>Sat, 06 Aug 2016 17:32:46 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/MIT-6.824-lab3-Fault-Tolerant-KVService-Implementation/</guid>
      <description>

&lt;p&gt;lab3 是基于 lab2 实现的 Raft Consensus Algorithm 之上实现 KV Service。主要分为两部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Part A：Key/value service without log compaction，即实现基本的分布式存储服务。&lt;/li&gt;
&lt;li&gt;Part B: Key/value service with log compaction，即在 Part A 基础上实现 log compaction。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;代码分别可以 pass 各个 test case，但所有一起跑时有时会卡在 &lt;code&gt;TestPersistPartition()&lt;/code&gt; 这里，初步猜测是 raft 的实现还有点 bug。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Wiesen/MIT-6.824/tree/master/2016/kvraft&#34;&gt;Code Link&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;part-a-key-value-service&#34;&gt;Part A：Key/value service&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;KV Database Client API&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;key/value database 的 client API 必须满足以下要求：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;保证仅执行一次(at most once semantics)：API 必须为每个 Client 及 每个 Request 赋予唯一的 id；&lt;/li&gt;
&lt;li&gt;必须向使用该 API 的应用提供 sequential consistency：对于每个 Client，仅有一条 Request RPC 在显式执行(利用 lock 实现)；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此外，API 应当一直尝试向 key/value server 发起 RPC 直到收到 positive reply；并且记住 leader id，从而尽可能避免失败次数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Raft Handler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Raft Server Handler 需要满足以下要求：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;保证每个 client 的每条 request (主要是写操作) 仅执行一次：对于重复的 request，仅向 client 回复操作结果；&lt;/p&gt;

&lt;p&gt;本文为每个 client 维护一个已执行的最大 requestId 值 (&lt;code&gt;map[int64]int&lt;/code&gt;)，从而检测并过滤重复的 request&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; func (kv *RaftKV) isDuplicated(clientId int64, requestId int) bool {
    kv.mu.Lock()
    defer kv.mu.Unlock()
    if value, ok := kv.ack[clientId]; ok &amp;amp;&amp;amp; value &amp;gt;= requestId {
        return true
    }
    kv.ack[clientId] = requestId
    return false
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在向 raft 添加等待结果的同时，需要一直监听返回管道 &lt;code&gt;applyCh&lt;/code&gt; ，以接收已经达成一致的 entry；&lt;/p&gt;

&lt;p&gt;我们开一个 goroutine &lt;code&gt;update()&lt;/code&gt; 一直监听 &lt;code&gt;applyCh&lt;/code&gt;，并且基于 entry 的 index 各维护一个管道 (&lt;code&gt;map[int]chan Result&lt;/code&gt;)，存放在 raft servers 间达成一致的 entry，等待 handler 的读取或者直接丢弃。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; func (kv *RaftKV) Update() {   // ignore snapshot
    for true {
        msg := &amp;lt;- kv.applyCh
        request := msg.Command.(Op)
        var result Result
        ...                     // set variable value
        result.reply = kv.Apply(request, kv.isDuplicated(clientId, requestId))
        kv.sendResult(msg.Index, result);
    }
  }

 func (kv *RaftKV) sendResult(index int, result Result) {
    kv.mu.Lock()
    defer kv.mu.Unlock()
    if _, ok := kv.messages[index]; !ok {
        kv.messages[index] = make(chan Result, 1)
    } else {
        select {
        case &amp;lt;- kv.messages[index]:
        default:
        }
    }
    kv.messages[index] &amp;lt;- result
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;key/value server 向 raft 添加一个 entry 后，阻塞读取其 index 对应的管道，直到接收到结果或者超时（本文设置为 1s）。当接收到的结果 clientId 或者 requestId 不一致时，表明 leader 已经发生了更替，由 Client 重新向 server 发起 RPC。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;有一个需要注意的地方是，&lt;strong&gt;必须利用 &lt;code&gt;gob.Register()&lt;/code&gt; 注册需要通过 RPC 发送的结构体&lt;/strong&gt;，这样结构体才能够被解析，否则发送过去就是一个 &lt;code&gt;nil&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;part-b-log-compaction&#34;&gt;Part B: log compaction&lt;/h2&gt;

&lt;p&gt;随着运行时间的增加，raft server 的 log table 会越来越大，不仅会占用越多空间，而且一旦出现宕机则 replay 也需要越长时间。比如不加以管理，则势必影响服务的可用性。为了令其维持合理长度不至于无限增加，必须在适当的时候抛弃旧的 log entries。&lt;/p&gt;

&lt;p&gt;这部分主要有以下实现点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Take snapshots independently&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里各个 raft server 各自独立进行 snapshot，而这并不会影响 raft 的一致性。因为数据始终从 leader 流向 follower，各个 raft server 只是将数据重新组织而已。&lt;/p&gt;

&lt;p&gt;这部分主要解决的问题是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(When)&lt;/strong&gt; 什么时候进行 snapshot：由 key/value server 检测所连接的 raft server 存储大小是否即将超过阈值，然后通知该 raft server 进行 snapshot；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(What)&lt;/strong&gt; 在 snapshot 中存储什么信息：如 raft-extended paper Figure 12 里的描述，主要包括当前 &lt;code&gt;LastIncludedIndex&lt;/code&gt;, &lt;code&gt;LastIncludedTerm&lt;/code&gt; 以及 &lt;code&gt;data&lt;/code&gt;，其中 &lt;code&gt;data&lt;/code&gt; 是状态机状态，来自于 key/value server。一点需要注意的是，必须保存用于检测 duplicate client requests 的数据，因此 &lt;code&gt;data&lt;/code&gt; 在这里包括整个数据库和检测重复的 map；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(How)&lt;/strong&gt; 如何令 raft 在仅有最新一部分 log 的情况下保持正常运行：主要是将 &lt;code&gt;rf.logTable[0]&lt;/code&gt; 作为起始 entry，一旦有 follower 请求更老的 entries，则应该发送 InstallSnapshot RPC；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要增加和修改的地方如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;update()&lt;/code&gt;： 在每次接收到 raft server 返回的 entry 时，检测 raft state size，若临近阈值则将封装 &lt;code&gt;data&lt;/code&gt;，然后通知 raft 从 &lt;code&gt;entry.index&lt;/code&gt; 开始 snapshotting；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;StartSnapshot(data []byte, index int)&lt;/code&gt;：删除 log table 中序号小于 &lt;code&gt;index&lt;/code&gt; 的 entries，并且在 &lt;code&gt;data&lt;/code&gt; 后添加最后包括的 entry 的相关数据，最后持久化保存；&lt;/li&gt;
&lt;li&gt;其余琐碎并且细节的修改还包括：对 entry 增加一个字段 &lt;code&gt;index&lt;/code&gt;，记录其在所在 &lt;code&gt;term&lt;/code&gt; 的序号，在需要对 log table 进行操作地方（尤其是涉及对 entry 在 table 中的位置），注意 log table 中的起始序号：&lt;code&gt;baseLogIndex := rf.logTable[0].Index&lt;/code&gt; 再进行处理；&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;InstallSnapshot RPC&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当一个 follower 远远落后于 leader（即无法在 log table 中找到匹配的 entry），则应该发送 InstallSnapshot RPC。我们参考 raft-extended paper Figure 13 设置数据结构，但有所简化：由于 lab 里的 Snapshot 不大，因此没有设置 chunk，也就是不需要对 snapshot 进行切分。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;InstallSnapshot RPC sender&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当 heartbeat timeout 时 leader 检测 follower 的 log table 是否与自身一致，如果 &lt;code&gt;rf.nextIndex[server] &amp;lt;= baseLogIndex&lt;/code&gt;，则 leader 应该向 follower &lt;code&gt;server&lt;/code&gt; 发送 InstallSnapshot RPC,否则 &lt;code&gt;AppendEntries&lt;/code&gt;。这里发送设置好相应的参数即可，跟发送 &lt;code&gt;AppendEntries&lt;/code&gt; 差不多，收到正确的 reply 则 更新 &lt;code&gt;matchIndex&lt;/code&gt; 和 &lt;code&gt;nextIndex&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; baseLogIndex := rf.logTable[0].Index
 if rf.nextIndex[server] &amp;lt;= baseLogIndex {
    ...             // set variable value
    var reply InstallSnapshotReply
    if rf.sendInstallSnapshot(server, args, &amp;amp;reply) {
        if rf.role != Leader {
            return
        }
        if args.Term != rf.currentTerm || reply.Term &amp;gt; args.Term {
            if reply.Term &amp;gt; args.Term {
                ... // update term and role
            }
            return
        }
        rf.matchIndex[server] = baseLogIndex
        rf.nextIndex[server] = baseLogIndex + 1
        return
    }
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;InstallSnapshot RPC handler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;由于没有设置 chunk，所以这里的 handler 比 paper 中的 implementation 简化不少：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先检测 &lt;code&gt;args.Term &amp;lt; rf.currentTerm&lt;/code&gt;，满足则直接返回自身 term 即可；&lt;/li&gt;
&lt;li&gt;其次检测 &lt;code&gt;rf.currentTerm &amp;lt; args.Term&lt;/code&gt;,满足则更新自身 term 和 role;&lt;/li&gt;
&lt;li&gt;然后更新自身的 log table，把 LastIncluded entry 前的丢弃；&lt;/li&gt;
&lt;li&gt;最后将 snapshot 发送给 key/value server，以重置数据库数据，更新状态。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;最后&#34;&gt;最后&lt;/h2&gt;

&lt;p&gt;写 lab3 的时候，对 lab2 的代码调整很大，发现了不少 bug 和逻辑不合理的地方，整体上对 raft 的理解更加深入了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MIT 6.824: lab2 Raft Consensus Algorithm Implementation</title>
      <link>http://wiesen.github.io/post/MIT-6.824-lab2-Raft-Consensus-Algorithm-Implementation/</link>
      <pubDate>Fri, 10 Jun 2016 21:32:46 +0800</pubDate>
      
      <guid>http://wiesen.github.io/post/MIT-6.824-lab2-Raft-Consensus-Algorithm-Implementation/</guid>
      <description>

&lt;p&gt;Raft 将一致性问题分为了三个相对独立的子问题，分别是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Leader election&lt;/strong&gt;：当前 leader 崩溃时，集群中必须选举出一个新的 leader；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Log replication&lt;/strong&gt;：leader 必须接受来自 clients 的 log entries，并且将其 replicate 到集群机器中，强制其余 logs 与其保持一致；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Safety&lt;/strong&gt;：Raft 中最关键的 safety property 是 State Machine Safety Property，亦即是，当任一机器 apply 了某一特定 log entry 到其 state machine 中，则其余服务器都不可能 apply 了一个 index 相同但 command 不同的 log。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;差不多依据上述划分，6.824 中 Raft 的实现指导逻辑还是挺清晰的，其中 safety property 由 Leader election 和 Log replication 共同承担，并且将 Persistence 作为最后一部分。实现过程主要分为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Leader Election and Heartbeats：首先令 Raft 能够在不存在故障的情景下选举出一个 leader，并且稳定保持状态；&lt;/li&gt;
&lt;li&gt;Log Replication：其次令 Raft 能够保持一个 consistent 并且 replicated 的 log；&lt;/li&gt;
&lt;li&gt;Persistence：最后令 Raft 能够持久化保存 persistent state，这样在重启后可以进行恢复。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中，本文主要参考 Raft paper，其中的 &lt;strong&gt;figure 2&lt;/strong&gt; 作用很大。本文实现&lt;strong&gt;大量依赖 channel 实现消息传递和线程同步&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Wiesen/MIT-6.824/blob/master/2016/raft/raft.go&#34;&gt;Code Link&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;leader-election-and-heartbeat&#34;&gt;Leader Election and Heartbeat&lt;/h2&gt;

&lt;p&gt;实现 Leader Election，主要是需要完成以下三个功能：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Role Transfer：state machine &amp;amp; election timer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先实现 Raft 的 sate machine，所有 server 都应当在初始化 Raft peer 时开启一个单独的线程来维护状态，令其在 Follower，Candidate，Leader 三个状态之间进行转换。&lt;/p&gt;

&lt;p&gt;有一点&lt;strong&gt;注意&lt;/strong&gt;的是，&lt;code&gt;nextIndex[]&lt;/code&gt; 和 &lt;code&gt;matchindex[]&lt;/code&gt; 需要在 election 后进行 reinitialize。&lt;/p&gt;

&lt;p&gt;func (rf *Raft) changeRole() {
        for true {
            switch rf.role {
            case Leader:
                for i := range rf.peers {
                    rf.nextIndex[i] = rf.logTable[len(rf.logTable)-1].Index + 1
                    rf.matchIndex[i] = 0
                }
                go rf.doHeartbeat()
                &amp;lt;-rf.chanRole
            case Candidate:
                chanQuitElect := make(chan bool)
                go rf.startElection(chanQuitElect)
                &amp;lt;-rf.chanRole
                close(chanQuitElect)
            case Follower:
                &amp;lt;-rf.chanRole
            }
        }
    }&lt;/p&gt;

&lt;p&gt;此外，定时器 election timer 的作用十分关键，所有 server 都应当在初始化 Raft peer 时开启一个单独的线程来维护 election timer。&lt;/p&gt;

&lt;p&gt;当 election timer 超时时，机器将会转换至 Candidate 状态。另外在以下三种情况下将会 reset 定时器：收到合法的 heartbeat message；投票给除自身以外的 candidate；自身启动election（本文视为转换为 Candidate 状态）。&lt;/p&gt;

&lt;p&gt;同样有一点需要注意，需要确保不同机器上的 timer 异步，也就是不会同时触发，否则所有机器都会自投票导致无法选举 leader。在 golang 中通过以时间作为种子投入到随机发生器中：&lt;code&gt;rand.Seed(time.Now().UnixNano())&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) startElectTimer() {
    floatInterval := int(RaftElectionTimeoutHigh - RaftElectionTimeoutLow)
    timeout := time.Duration(rand.Intn(floatInterval)) + RaftElectionTimeoutLow
    electTimer := time.NewTimer(timeout)
    for {
        select {
        case &amp;lt;- rf.chanHeartbeat: // received valid heartbeat message
            rf.resetElectTimer(electTimer)
        case &amp;lt;- rf.chanGrantVote: // voted for other server 
            rf.resetElectTimer(electTimer)
        case &amp;lt;-electTimer.C:      // fired election  
            rf.chanRole &amp;lt;- Candidate
            rf.resetElectTimer(electTimer)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;RequstVote RPC 的 sender 和 handler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;完成 Raft 的 sate machine后，开始实现 Raft 中的 RequestVote 操作，使得能够选举出一个 leader。&lt;/p&gt;

&lt;p&gt;机器处于 Candidate 状态时应当启动 election：&lt;code&gt;currentTerm++&lt;/code&gt; -&amp;gt; &lt;code&gt;votedFor = me&lt;/code&gt; -&amp;gt; &lt;code&gt;sendRequestVote()&lt;/code&gt;。其中 &lt;code&gt;sendRequestVote()&lt;/code&gt; 应当异步，也就是并发给其余机器发送 RequstVote。&lt;/p&gt;

&lt;p&gt;当出现以下情况，当前 election 过程终结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;获得大多数机器的投票 -&amp;gt; 转换为 Leader 状态；&lt;/li&gt;
&lt;li&gt;接受到的 reply 中 &lt;code&gt;term T &amp;gt; currentTerm&lt;/code&gt; -&amp;gt; 更新 &lt;code&gt;currentTerm&lt;/code&gt;，转换为 Follower 状态；&lt;/li&gt;
&lt;li&gt;election timer 超时 -&amp;gt; 终结当前 election，并且启动新一轮 election，保持 Candidate 状态；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个机器接收到 RequstVote RPC，需要决定是否投票：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果 RequstVote RPC 中的 &lt;code&gt;term T &amp;lt; currentTerm&lt;/code&gt;，直接返回 false 拒绝投票即可；&lt;/li&gt;
&lt;li&gt;如果 RequstVote RPC 中的 &lt;code&gt;term T &amp;gt; currentTerm&lt;/code&gt;，则需要更新 &lt;code&gt;currentTerm&lt;/code&gt;，转换为 Follower 状态；&lt;/li&gt;
&lt;li&gt;如果该机器在 &lt;code&gt;currentTerm&lt;/code&gt; 已经投票，则直接返回 false 拒绝投票；&lt;/li&gt;
&lt;li&gt;否则在满足 &amp;ldquo;Candidate&amp;rsquo;s log is at least as up-to-date as receiver&amp;rsquo;s log&amp;rdquo; 时返回 true 投票，并且 reset election timeout；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所谓 &lt;strong&gt;“up-to-date”&lt;/strong&gt; 简单来说就是：比较两个 log 中的最后一条 entry 的 &lt;code&gt;index&lt;/code&gt; 和 &lt;code&gt;term&lt;/code&gt;：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当两个 log 的最后一条 entry 的 term 不同，则 &lt;strong&gt;later&lt;/strong&gt; term is more up-to-date；&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当两个 log 的最后一条 entry 的 term 相同，则 whichever log is &lt;strong&gt;longer&lt;/strong&gt; is more up-to-date&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// RequestVote RPC handler.
func (rf *Raft) RequestVote(args RequestVoteArgs, reply *RequestVoteReply) {
  if rf.currentTerm &amp;gt; args.Term {
    reply.Term = rf.currentTerm
        reply.VoteGranted = false
    return
  }
  if rf.currentTerm &amp;lt; args.Term {
    rf.currentTerm = args.Term
    rf.votedFor = -1
    rf.chanRole &amp;lt;- Follower
  }
  reply.Term = args.Term
  if rf.votedFor != -1 &amp;amp;&amp;amp; rf.votedFor != args.CandidateId {
    reply.VoteGranted = false
  } else if rf.logTable[len(rf.logTable)-1].Term &amp;gt; args.LastLogTerm {
    reply.VoteGranted = false   //! different term
  } else if len(rf.logTable)-1 &amp;gt; args.LastLogIndex &amp;amp;&amp;amp; rf.logTable[len(rf.logTable)-1].Term == args.LastLogTerm { 
    reply.VoteGranted = false   //! same term but different index
  }else {
    reply.VoteGranted = true
    rf.votedFor = args.CandidateId
    rf.chanGrantVote &amp;lt;- true
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Heartbeat 的 sender 和 handler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最后实现 Raft 中的 Heartbeat 操作，能够令 Leader 稳定保持状态。&lt;/p&gt;

&lt;p&gt;机器处于 Leader 状态时应当启动 heartbeat，而其实际上就是不含 log entry 的 AppendEntries（只需要检测某一机器的 log 是否最新）。&lt;/p&gt;

&lt;p&gt;其中 &lt;code&gt;sendHeartbeat()&lt;/code&gt; 应当异步，也就是并发给其余机器发送 heartbeat。每一个 heartbeat 线程利用 timer 来周期性地触发操作。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) sendHeartbeat(server int) {
    for rf.getRole() == Leader {
                rf.doAppendEntries(server)  // later explain in Log Replication
                heartbeatTimer.Reset(RaftHeartbeatPeriod)
                &amp;lt;-heartbeatTimer.C
        }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一个机器接收到不含 log entry 的 AppendEntries RPC（也就是 heartbeat）时，需要决定是否更新自身的 term 和 leaderId：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果 AppendEntries RPC 中的 &lt;code&gt;term T &amp;lt; currentTerm&lt;/code&gt;，则 reply 中返回 &lt;code&gt;currentTerm&lt;/code&gt; 让发送方更新；&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果 RequstVote RPC 中的 &lt;code&gt;term T &amp;gt; currentTerm&lt;/code&gt;，则需要更新 &lt;code&gt;currentTerm&lt;/code&gt; 和 &lt;code&gt;leaderId&lt;/code&gt;，转换为 Follower 状态，并且 reset election timeout；&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// temporary AppendEntries RPC handler.
func (rf *Raft) AppendEntries(args AppendEntriesArgs, reply *AppendEntriesReply) {
    if args.Term &amp;lt; rf.currentTerm {
        reply.Term = rf.currentTerm
        reply.Success = false
        return
    }
    //! update current term and only one leader granted in one term
    if rf.currentTerm &amp;lt; args.Term {
        rf.currentTerm = args.Term
        rf.votedFor = -1
        rf.leaderId = args.LeaderId
        rf.chanRole &amp;lt;- Follower
    }
    rf.chanHeartbeat &amp;lt;- true
    reply.Term = args.Term
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;log-replication&#34;&gt;Log Replication&lt;/h2&gt;

&lt;p&gt;完成了 Leader election 后，下一步是令 Raft 保持一个 consistent 并且 replicated 的 log。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;AppendEntries RPC sender&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在 Raft 中，只有 leader 允许添加 log，并且通过发送含有 log 的 AppendEntries RPC 给其余机器令其 log 保持一致。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) Replica() {
// replica log
for server := range rf.peers {
    if server != rf.me {
        go rf.doAppendEntries(server)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来主要是 &lt;code&gt;doAppendEntries(server int)&lt;/code&gt; 的实现细节。&lt;/p&gt;

&lt;p&gt;当 Leader 的 log 比某 server 长时，亦即是 &lt;code&gt;rf.nextIndex[server] &amp;lt; len(rf.logTable)&lt;/code&gt;，则需要发送 entry&lt;/p&gt;

&lt;p&gt;有一点要&lt;strong&gt;注意&lt;/strong&gt;的是：Leader 在对某 server 进行上述的连续发送时间或者等待 reply 的时间可能会大于 heartbeat timeout，因此触发 AppendEntries RPC。然而 Leader 本身正在等待 reply，这时候重复发送是多余的。&lt;/p&gt;

&lt;p&gt;本文检测 Leader 是否在向某 server 发送 AppendEntries RPC，若是则直接退出不再重复操作：这里设计为 Leader 为每一 server 维护一个带有&lt;strong&gt;一个缓存&lt;/strong&gt;的管道，这样某 server 进行 AppendEntries RPC 前可以确认是否正在处理。&lt;/p&gt;

&lt;p&gt;最后如果 RPC failed 则直接退出，否则收到 AppendEntries RPC 的 reply 时：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先判断是否 &lt;code&gt;reply.Term &amp;gt; args.Term&lt;/code&gt;，若是则 Leader 需要更新自身 currentTerm，并且转换为 Follower 状态。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;若 &lt;code&gt;reply.Success&lt;/code&gt; 会表明达成一致，更新 &lt;code&gt;rf.matchIndex[server]&lt;/code&gt; 和 &lt;code&gt;rf.nextIndex[server]&lt;/code&gt;；否则仅更新 &lt;code&gt;rf.nextIndex[server]&lt;/code&gt;（这里涉及到 3 中的优化）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) doAppendEntries(server int) {
    //! make a lock for every follower to serialize
    select {
    case &amp;lt;- rf.chanAppend[server]:
    default: return
    }
    defer func() {rf.chanAppend[server] &amp;lt;- true}()

    for rf.getRole() == Leader {
        rf.mu.Lock()
        var args AppendEntriesArgs
        ...             // set variable value
        if rf.nextIndex[server] &amp;lt; len(rf.logTable) {
            args.Entry = rf.logTable[rf.nextIndex[server]:]
        }
        rf.mu.Unlock()

        var reply AppendEntriesReply
        if rf.sendAppendEntries(server, args, &amp;amp;reply) {
            if rf.role != Leader {
                return
            }
            if args.Term != rf.currentTerm || reply.Term &amp;gt; args.Term {
                if reply.Term &amp;gt; args.Term {
                    ... // update term and role
                }
                return
            }
            if reply.Success {
                rf.matchIndex[server] = reply.NextIndex - 1
                rf.nextIndex[server] = reply.NextIndex
            } else {
                rf.nextIndex[server] = reply.NextIndex
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;AppendEntries RPC handler&lt;/strong&gt; (2016.8.5 Update)&lt;/p&gt;

&lt;p&gt;一个机器接收到含有 log entry 的 AppendEntries RPC，前一部分跟处理 heartbeat 一样，剩下的部分则是决定是否更新自身的 log。根据 Raft paper 中的 figure 2 按部就班实现就好了。&lt;/p&gt;

&lt;p&gt;Update：处理 log entries array 还是需要注意一下：首先决定是否更新 log table，当满足条件决定更新后，主要存在三种更新情况：（1）更新旧 index；（2）更新旧 index，且添加新 index；（3）仅添加新 index。（如下图）&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://7vij5d.com1.z0.glb.clouddn.com/raft-appendentries.bmp&#34; alt=&#34;raft-appendentries&#34; /&gt;&lt;/p&gt;

&lt;p&gt;本文方法是：首先记录下当前开始处理的 &lt;code&gt;basicIndex := args.PrevLogIndex + 1&lt;/code&gt;（即 &lt;code&gt;args.Entry&lt;/code&gt; 中的起始 index），然后遍历 &lt;code&gt;args.Entry&lt;/code&gt;，一旦 index 已达 logTable 末端或者某个 entry 的 term 不匹配，则清除 logTable 中当前及后续的 entry，并且将 &lt;code&gt;args.Entry&lt;/code&gt; 的当前及后续 entry 添加到 logTable中。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;AppendEntries RPC optimization&lt;/strong&gt; (2016.8.5 Update)&lt;/p&gt;

&lt;p&gt;这一部分主要是优化 AppendEntries RPC，当发生拒绝 append 时减少 master 需要发送 RPC 的次数。虽然 Raft paper 中怀疑这个优化操作是否有必要，但 lab2 中有些 unreliable test case 就需要你实现这个优化操作…&lt;/p&gt;

&lt;p&gt;首先需要在 struct AppendEntriesReply 中添加两个数据：&lt;code&gt;NextIndex int&lt;/code&gt;,  &lt;code&gt;FailTerm int&lt;/code&gt;，分别用于指示 conflicting entry 所在 term，以及在该 term 中存储的第一个 entry 的 index；&lt;/p&gt;

&lt;p&gt;在 handler 的优化如下：如果 log unmatched，存在两种情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;len(rf.logTable) &amp;lt;= args.PrevLogIndex&lt;/code&gt;：则直接返回 &lt;code&gt;NextIndex = len(rf.logTable)&lt;/code&gt; 即可；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rf.logTable[args.PrevLogIndex].Term != args.PrevLogTerm&lt;/code&gt;：首先记录 &lt;code&gt;FailTerm&lt;/code&gt;，然后从当前 conflicting entry 开始向前扫描，直到 index 为 0 或者 term 不匹配，然后记录下该 term 的第一个 index；
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在 sender 的优化如下：当 append 失败时，如果 &lt;code&gt;NextIndex &amp;gt; matchIndex[server]&lt;/code&gt;，则 &lt;code&gt;nextIndex[server]&lt;/code&gt; 直接退至 &lt;code&gt;NextIndex&lt;/code&gt;，减少了需要尝试 append 的 RPC 次数；否则 &lt;code&gt;nextIndex[server]&lt;/code&gt; 退回到 &lt;code&gt;matchIndex[server] + 1&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;STEP 4. Apply committed entries to local service replica&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于 Leader 而言，需要不断检测当前 term 的 log entry 的 replica 操作是否完成，然后进行 commit 操作。&lt;/p&gt;

&lt;p&gt;当超过半数的机器已经完成 replica 操作，则 Leader 认为该条 log entry 可以 commit。&lt;/p&gt;

&lt;p&gt;一旦当前 term 的某条 log entry L 是通过上述方式 commit 的，则根据 Raft 的 &lt;strong&gt;Log Matching Property&lt;/strong&gt;，Leader 可以 commit 先于 L 添加到 log 的所有 entry。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (rf *Raft) updateLeaderCommit() {
    rf.mu.Lock()
    defer rf.mu.Unlock()
    defer rf.persist()
    oldIndex := rf.commitIndex
    newIndex := oldIndex
    for i := len(rf.logTable)-1; i&amp;gt;oldIndex &amp;amp;&amp;amp; rf.logTable[i].Term==rf.getCurrentTerm(); i-- {
        countServer := 1
        for server := range rf.peers {
            if server != rf.me &amp;amp;&amp;amp; rf.matchIndex[server] &amp;gt;= i {
                countServer++
            }
        }
        if countServer &amp;gt; len(rf.peers) / 2 {
            newIndex = i
            break
        }
    }
    if oldIndex == newIndex {
        return
    }
    rf.commitIndex = newIndex

    //! update the log added in previous term
    for i := oldIndex + 1; i &amp;lt;= newIndex; i++ {
        rf.chanCommitted &amp;lt;- ApplyMsg{Index:i, Command:rf.logTable[i].Command}
        rf.lastApplied = i
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于 Follower 而言，则：&lt;code&gt;commitIndex = min(leaderCommit, index of last new entry)&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;persistence&#34;&gt;Persistence&lt;/h2&gt;

&lt;p&gt;最后一步是持久化保存 persistent state，不过在 lab2 仅是通过 &lt;code&gt;persister&lt;/code&gt; object 来保存，并没有真正使用到磁盘。实现了这一部分后可以稳定地 pass 掉关于 Persist 的 test case。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Read persist&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在 Make Raft peer 时读取 persister。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Write persist&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;修改了 Raft 的 persistent state 后应当及时写至 persister，主要是在以下几个地方插入 write：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动了 election 修改了自身的 persistent state后；&lt;/li&gt;
&lt;li&gt;受到了 RequestVote RPC 和 AppendEntries RPC 的 reply，得知需要更新自身的 persistent state 后；&lt;/li&gt;
&lt;li&gt;RequestVote RPC handler 和 AppendEntries RPC handler 处理完毕后；&lt;/li&gt;
&lt;li&gt;Leader 收到 client 的请求命令，添加到自身的 log 后。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;defect&#34;&gt;Defect&lt;/h2&gt;

&lt;p&gt;本文还有些不足，有待后续优化。主要是&lt;strong&gt;不能稳定地&lt;/strong&gt; pass &lt;code&gt;TestUnreliableAgree()&lt;/code&gt; + &lt;strong&gt;不能&lt;/strong&gt; pass &lt;code&gt;TestFigure8Unreliable()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To Be Continue&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;2016-8-11-update&#34;&gt;2016-8-11 Update&lt;/h2&gt;

&lt;p&gt;最近几天 debug 了之前的代码，发现了若干个问题。目前的代码实现已经&lt;strong&gt;比较稳定&lt;/strong&gt;地 pass 所有的 test case，上面的代码段也已经修改了。但仍然存在一个 bug: 在过 TestUnreliableAgree() 时 fail to reach agreement。这个 bug 的触发几率很低，还没想明白哪里出问题。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;LEADER ELECTION: Role Transfer (state machine)&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;之前实现 server state machine 的方法是利用 channel 来进行状态修改操作，并且会新开一个 goroutine 进行该状态死循环，而没有其他状态的处理逻辑。本文由一个 goroutine 阻塞读取该 channel，从而处理 server 的状态转换。然而，channel 同步是存在延时的，只有在当前 goroutine 被挂起或者休眠等时，才会转去处理。&lt;/p&gt;

&lt;p&gt;这样的方法存在一个 bug：新 Leader 产生后，旧 Leader 收到消息应该更新自身的 term 并且转换为 Follower；然而由于 channel 同步并非立即执行，旧 Leader 在自身状态被重新赋值前仍然会执行 Leader 的代码；这时候就会出现两个 Leader 同时处理 RPC。&lt;/p&gt;

&lt;p&gt;因此，修改的内容是：去掉 channel 同步方法，当需要进行状态转换时，立即修改 server 的状态，终止该 server 当前状态的执行。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;LOG REPLICATION: AppendEntries RPC&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;之前不能 pass &lt;code&gt;TestUnreliableAgree()&lt;/code&gt; 和 &lt;code&gt;TestFigure8Unreliable()&lt;/code&gt; 时丝毫没有提示，只能等程序运行时间过长然后被杀死。后来思考了一下问题原因：&lt;strong&gt;程序运行过慢，跟不上 test case 要求的速度，所以后续的测试代码也根本没有执行&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;然后发现程序执行慢的原因是：Leader 发送 AppendEntries RPC 每次仅携带一条 log entry，导致 server 无法快速 catch up。所以修改的主要内容就是：AppendEntries RPC 每次携带从 &lt;code&gt;nextIndex&lt;/code&gt; 直到最新的 log entries。&lt;/p&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://www.douban.com/note/549229678/&#34;&gt;MIT 6.824 Week 3 notes&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>